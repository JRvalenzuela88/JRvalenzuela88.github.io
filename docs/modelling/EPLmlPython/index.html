
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation, guides and articles on creating, developing and implementing automated betting strategies, using data analysis to inform betting models and how to interact with the Betfair API.">
      
      
        <meta name="author" content="Betfair Data Scientists">
      
      
        <link rel="canonical" href="https://betfair-datascientists.github.io/modelling/EPLmlPython/">
      
      <link rel="icon" href="../../img/BetfairFavicon.ico">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.6">
    
    
      
        <title>EPL ML walk through in Python - The Automation Hub</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.cd566b2a.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/betfair.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#epl-machine-learning-walkthrough" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      
  
  <header class="md-header" data-md-component="header">
    <nav class="md-header__inner md-grid" aria-label="Header">
      <a href="../.." title="The Automation Hub" class="md-header__button md-logo" aria-label="The Automation Hub" data-md-component="logo">
        
  <img src="../../img/logo.svg" alt="logo">

      </a>
      <label class="md-header__button md-icon" for="__drawer">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
      </label>
      <div class="md-header__title" data-md-component="header-title">
        <div class="md-header__ellipsis">
          <div class="md-header__topic">
            <span class="md-ellipsis">
              The Automation Hub
            </span>
          </div>
          <div class="md-header__topic" data-md-component="header-topic">
            <span class="md-ellipsis">
              
                EPL ML walk through in Python
              
            </span>
          </div>
        </div>
      </div>
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
              </label>
            
          
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3z"/></svg>
              </label>
            
          
        </form>
      
      
      
        <label class="md-header__button md-icon" for="__search">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
      
    </nav>
    
  </header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="The Automation Hub" class="md-nav__button md-logo" aria-label="The Automation Hub" data-md-component="logo">
      
  <img src="../../img/logo.svg" alt="logo">

    </a>
    The Automation Hub
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Home
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Home" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Home
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        The Automation Hub
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/apiResources/" class="md-nav__link">
        API resources
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/apiappkey/" class="md-nav__link">
        How to access the Betfair API
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_3">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/apiRtutorial/" class="md-nav__link">
        API tutorials in R
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/apiPythontutorial/" class="md-nav__link">
        API tutorial in Python
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/GoldenRulesofAutomation/" class="md-nav__link">
        Golden rules of automation
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Historic Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Historic Data" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Historic Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../historicData/dataSources/" class="md-nav__link">
        Pricing Data Sources
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../historicData/jsonToCsvTutorial/" class="md-nav__link">
        JSON to CSV in Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../historicData/backtestingRatingsTutorial/" class="md-nav__link">
        Back testing ratings in Python
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_3">
          Historic Data site
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Historic Data site" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Historic Data site
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../historicData/usingHistoricDataSite/" class="md-nav__link">
        Downloading from the Historic Data site
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Modelling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Modelling" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Modelling
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../howToModel/" class="md-nav__link">
        Intro to modelling
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Soccer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Soccer" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Soccer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../soccerEloTutorialR/" class="md-nav__link">
        Elo soccer tutorial in R
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../soccerModellingTutorialPython/" class="md-nav__link">
        Soccer modelling tutorial in Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../soccerModellingTutorialR/" class="md-nav__link">
        Soccer modelling tutorial in R
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        EPL ML walk through in Python
      </a>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          AFL
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="AFL" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          AFL
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../AFLmodellingPython/" class="md-nav__link">
        AFL modelling walk through in Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../brownlowModelTutorial/" class="md-nav__link">
        Modelling the Brownlow Medal in Python
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_4" type="checkbox" id="__nav_4_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_4">
          Tennis
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tennis" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          Tennis
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../howToModelTheAusOpen/" class="md-nav__link">
        How to model the Australian Open
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../AusOpenRTutorial/" class="md-nav__link">
        Aus Open R Tutorial
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../AusOpenPythonTutorial/" class="md-nav__link">
        Aus Open Python Tutorial
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Auto Tools
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Auto Tools" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Auto Tools
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/overview/" class="md-nav__link">
        Tools Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_2">
          Bet Angel
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Bet Angel" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Bet Angel
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngel/betAngel/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelbeginners/" class="md-nav__link">
        Beginner's guide
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelintermediate/" class="md-nav__link">
        Intermediate guide
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngeladvanced/" class="md-nav__link">
        Advanced guide
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelRatingsAutomation/" class="md-nav__link">
        Ratings auto
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelMarketFavouriteAutomation/" class="md-nav__link">
        Market fav auto
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelTippingAutomation/" class="md-nav__link">
        Tipping auto
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelSimultaneousMarkets/" class="md-nav__link">
        Simultaneous markets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/betAngelKellyStake/" class="md-nav__link">
        Kelly criterion staking
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3" type="checkbox" id="__nav_5_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_3">
          Gruss Betting Assistant
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Gruss Betting Assistant" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          Gruss Betting Assistant
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/Gruss/Gruss/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/GrussSettingupbasicmarketview/" class="md-nav__link">
        Setup basic market view and one click betting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/grussRatingsAutomation/" class="md-nav__link">
        Ratings auto
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/grussMarketFavouriteAutomation/" class="md-nav__link">
        Market fav auto
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/grusslSimultaneousMarkets/" class="md-nav__link">
        Simultaneous markets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/grussKellyStake/" class="md-nav__link">
        Kelly criterion staking
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_4" type="checkbox" id="__nav_5_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_4">
          Cymatic Trader
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Cymatic Trader" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_4">
          <span class="md-nav__icon md-icon"></span>
          Cymatic Trader
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/CymaticTrader/CymaticTrader/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/cymaticTraderRatingsAutomation/" class="md-nav__link">
        Ratings auto
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_5" type="checkbox" id="__nav_5_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_5">
          Geeks Toy
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Geeks Toy" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_5">
          <span class="md-nav__icon md-icon"></span>
          Geeks Toy
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/GeeksToyinstallationandsetup/" class="md-nav__link">
        Installation and setup
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/GeeksToybasicmarketviewstakingandoneclickbetting/" class="md-nav__link">
        Setup basic market view and one click betting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../autoTools/geeksToyRefreshSettings/" class="md-nav__link">
        Optimising refresh settings
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<h1 id="epl-machine-learning-walkthrough">EPL Machine Learning Walkthrough</h1>
<hr />
<h1 id="01-data-acquisition-exploration">01. Data Acquisition &amp; Exploration</h1>
<p>Welcome to the first part of this Machine Learning Walkthrough. This tutorial will be made of two parts; how we actually acquired our data (programmatically) and exploring the data to find potential features to use in the <a href="/modelling/EPLmodelPart2">next tutorial</a>.</p>
<hr />
<h2 id="data-acquisition">Data Acquisition</h2>
<p>We will be grabbing our data from <a href="http://www.football-data.co.uk/englandm.php">football-data.co.uk</a>, which has an enormous amount of soccer data dating back to the 90s. They also generously allow us to use it for free! However, the data is in separate CSVs based on the season. That means we would need to manually download 20 different files if we wanted the past 20 seasons. Rather than do this laborious and boring task, let's create a function which downloads the files for us, and appends them all into one big CSV.</p>
<p>To do this, we will use BeautifulSoup, a Python library which helps to pull data from HTML and XML files. We will then define a function which collates all the data for us into one DataFrame.</p>
<pre><code class="language-python"># Import Modules

import pandas as pd
import requests
from bs4 import BeautifulSoup
import datetime
pd.set_option('display.max_columns', 100)
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
from data_preparation_functions import *
</code></pre>
<pre><code class="language-python">def grab_epl_data():
    # Connect to football-data.co.uk
    res = requests.get(&quot;http://www.football-data.co.uk/englandm.php&quot;)

    # Create a BeautifulSoup object
    soup = BeautifulSoup(res.content, 'lxml')

    # Find the tables with the links to the data in them.
    table = soup.find_all('table', {'align': 'center', 'cellspacing': '0', 'width': '800'})[1]
    body = table.find_all('td', {'valign': 'top'})[1]

    # Grab the urls for the csv files
    links = [link.get('href') for link in body.find_all('a')]
    links_text = [link_text.text for link_text in body.find_all('a')]

    data_urls = []

    # Create a list of links
    prefix = 'http://www.football-data.co.uk/'
    for i, text in enumerate(links_text):
        if text == 'Premier League':
            data_urls.append(prefix + links[i])

    # Get rid of last 11 uls as these don't include match stats and odds, and we
    # only want from 2005 onwards
    data_urls = data_urls[:-12]

    df = pd.DataFrame()

    # Iterate over the urls
    for url in data_urls:
        # Get the season and make it a column
        season = url.split('/')[4]

        print(f&quot;Getting data for season {season}&quot;)

        # Read the data from the url into a DataFrame
        temp_df = pd.read_csv(url)
        temp_df['season'] = season

        # Create helpful columns like Day, Month, Year, Date etc. so that our data is clean
        temp_df = (temp_df.dropna(axis='columns', thresh=temp_df.shape[0]-30)
                          .assign(Day=lambda df: df.Date.str.split('/').str[0],
                                  Month=lambda df: df.Date.str.split('/').str[1],
                                  Year=lambda df: df.Date.str.split('/').str[2])
                          .assign(Date=lambda df: df.Month + '/' + df.Day + '/' + df.Year)
                          .assign(Date=lambda df: pd.to_datetime(df.Date))
                          .dropna())

        # Append the temp_df to the main df
        df = df.append(temp_df, sort=True)

    # Drop all NAs
    df = df.dropna(axis=1).dropna().sort_values(by='Date')
    print(&quot;Finished grabbing data.&quot;)

    return df
</code></pre>
<pre><code class="language-python">df = grab_epl_data()
# df.to_csv(&quot;data/epl_data.csv&quot;, index=False)

    Getting data for season 1819
    Getting data for season 1718
    Getting data for season 1617
    Getting data for season 1516
    Getting data for season 1415
    Getting data for season 1314
    Getting data for season 1213
    Getting data for season 1112
    Getting data for season 1011
    Getting data for season 0910
    Getting data for season 0809
    Getting data for season 0708
    Getting data for season 0607
    Getting data for season 0506
    Finished grabbing data.
</code></pre>
<p>Whenever we want to update our data (for example if we want the most recent Gameweek included), all we have to do is run that function and then save the data to a csv with the commented out line above.</p>
<hr />
<h2 id="data-exploration">Data Exploration</h2>
<p>Now that we have our data, let's explore it. Let's first look at home team win rates since 2005 to see if there is a consistent trend. To get an idea of what our data looks like, we'll look at the tail of the dataset first.</p>
<pre><code class="language-python">df.tail(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>AC</th>
<th>AF</th>
<th>AR</th>
<th>AS</th>
<th>AST</th>
<th>AY</th>
<th>AwayTeam</th>
<th>B365A</th>
<th>B365D</th>
<th>B365H</th>
<th>BWA</th>
<th>BWD</th>
<th>BWH</th>
<th>Bb1X2</th>
<th>BbAH</th>
<th>BbAHh</th>
<th>BbAv&lt;2.5</th>
<th>BbAv&gt;2.5</th>
<th>BbAvA</th>
<th>BbAvAHA</th>
<th>BbAvAHH</th>
<th>BbAvD</th>
<th>BbAvH</th>
<th>BbMx&lt;2.5</th>
<th>BbMx&gt;2.5</th>
<th>BbMxA</th>
<th>BbMxAHA</th>
<th>BbMxAHH</th>
<th>BbMxD</th>
<th>BbMxH</th>
<th>BbOU</th>
<th>Date</th>
<th>Day</th>
<th>Div</th>
<th>FTAG</th>
<th>FTHG</th>
<th>FTR</th>
<th>HC</th>
<th>HF</th>
<th>HR</th>
<th>HS</th>
<th>HST</th>
<th>HTAG</th>
<th>HTHG</th>
<th>HTR</th>
<th>HY</th>
<th>HomeTeam</th>
<th>IWA</th>
<th>IWD</th>
<th>IWH</th>
<th>LBA</th>
<th>LBD</th>
<th>LBH</th>
<th>Month</th>
<th>Referee</th>
<th>VCA</th>
<th>VCD</th>
<th>VCH</th>
<th>Year</th>
<th>season</th>
</tr>
</thead>
<tbody>
<tr>
<td>28</td>
<td>3.0</td>
<td>11.0</td>
<td>0.0</td>
<td>9.0</td>
<td>3.0</td>
<td>2.0</td>
<td>Crystal Palace</td>
<td>3.00</td>
<td>3.25</td>
<td>2.60</td>
<td>2.95</td>
<td>3.1</td>
<td>2.55</td>
<td>42.0</td>
<td>20.0</td>
<td>-0.25</td>
<td>1.71</td>
<td>2.13</td>
<td>2.92</td>
<td>1.73</td>
<td>2.16</td>
<td>3.22</td>
<td>2.55</td>
<td>1.79</td>
<td>2.21</td>
<td>3.04</td>
<td>1.77</td>
<td>2.23</td>
<td>3.36</td>
<td>2.66</td>
<td>39.0</td>
<td>2018-08-26</td>
<td>26</td>
<td>E0</td>
<td>1.0</td>
<td>2.0</td>
<td>H</td>
<td>6.0</td>
<td>14.0</td>
<td>0.0</td>
<td>13.0</td>
<td>5.0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>4.0</td>
<td>Watford</td>
<td>2.95</td>
<td>3.20</td>
<td>2.5</td>
<td>2.90</td>
<td>3.1</td>
<td>2.50</td>
<td>08</td>
<td>A Taylor</td>
<td>2.90</td>
<td>3.3</td>
<td>2.6</td>
<td>18</td>
<td>1819</td>
</tr>
<tr>
<td>27</td>
<td>5.0</td>
<td>8.0</td>
<td>0.0</td>
<td>15.0</td>
<td>3.0</td>
<td>1.0</td>
<td>Chelsea</td>
<td>1.66</td>
<td>4.00</td>
<td>5.75</td>
<td>1.67</td>
<td>3.8</td>
<td>5.25</td>
<td>42.0</td>
<td>22.0</td>
<td>1.00</td>
<td>1.92</td>
<td>1.88</td>
<td>1.67</td>
<td>2.18</td>
<td>1.71</td>
<td>3.90</td>
<td>5.25</td>
<td>2.01</td>
<td>1.95</td>
<td>1.71</td>
<td>2.28</td>
<td>1.76</td>
<td>4.17</td>
<td>5.75</td>
<td>40.0</td>
<td>2018-08-26</td>
<td>26</td>
<td>E0</td>
<td>2.0</td>
<td>1.0</td>
<td>A</td>
<td>4.0</td>
<td>16.0</td>
<td>0.0</td>
<td>6.0</td>
<td>2.0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>3.0</td>
<td>Newcastle</td>
<td>1.70</td>
<td>3.75</td>
<td>5.0</td>
<td>1.67</td>
<td>3.8</td>
<td>5.25</td>
<td>08</td>
<td>P Tierney</td>
<td>1.67</td>
<td>4.0</td>
<td>5.5</td>
<td>18</td>
<td>1819</td>
</tr>
<tr>
<td>29</td>
<td>2.0</td>
<td>16.0</td>
<td>0.0</td>
<td>9.0</td>
<td>5.0</td>
<td>4.0</td>
<td>Tottenham</td>
<td>2.90</td>
<td>3.30</td>
<td>2.62</td>
<td>2.90</td>
<td>3.2</td>
<td>2.55</td>
<td>42.0</td>
<td>20.0</td>
<td>-0.25</td>
<td>1.79</td>
<td>2.03</td>
<td>2.86</td>
<td>1.72</td>
<td>2.18</td>
<td>3.27</td>
<td>2.56</td>
<td>1.84</td>
<td>2.10</td>
<td>3.00</td>
<td>1.76</td>
<td>2.25</td>
<td>3.40</td>
<td>2.67</td>
<td>40.0</td>
<td>2018-08-27</td>
<td>27</td>
<td>E0</td>
<td>3.0</td>
<td>0.0</td>
<td>A</td>
<td>5.0</td>
<td>11.0</td>
<td>0.0</td>
<td>23.0</td>
<td>5.0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>2.0</td>
<td>Man United</td>
<td>2.75</td>
<td>3.25</td>
<td>2.6</td>
<td>2.75</td>
<td>3.2</td>
<td>2.55</td>
<td>08</td>
<td>C Pawson</td>
<td>2.90</td>
<td>3.3</td>
<td>2.6</td>
<td>18</td>
<td>1819</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># Create Home Win, Draw Win and Away Win columns
df = df.assign(homeWin=lambda df: df.apply(lambda row: 1 if row.FTHG &gt; row.FTAG else 0, axis='columns'),
              draw=lambda df: df.apply(lambda row: 1 if row.FTHG == row.FTAG else 0, axis='columns'),
              awayWin=lambda df: df.apply(lambda row: 1 if row.FTHG &lt; row.FTAG else 0, axis='columns'))
</code></pre>
<h3 id="home-ground-advantage">Home Ground Advantage</h3>
<pre><code class="language-python">win_rates = \
(df.groupby('season')
    .mean()
    .loc[:, ['homeWin', 'draw', 'awayWin']])

win_rates
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>homeWin</th>
<th>draw</th>
<th>awayWin</th>
</tr>
</thead>
<tbody>
<tr>
<td>season</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>0506</td>
<td>0.505263</td>
<td>0.202632</td>
<td>0.292105</td>
</tr>
<tr>
<td>0607</td>
<td>0.477573</td>
<td>0.258575</td>
<td>0.263852</td>
</tr>
<tr>
<td>0708</td>
<td>0.463158</td>
<td>0.263158</td>
<td>0.273684</td>
</tr>
<tr>
<td>0809</td>
<td>0.453826</td>
<td>0.255937</td>
<td>0.290237</td>
</tr>
<tr>
<td>0910</td>
<td>0.507895</td>
<td>0.252632</td>
<td>0.239474</td>
</tr>
<tr>
<td>1011</td>
<td>0.471053</td>
<td>0.292105</td>
<td>0.236842</td>
</tr>
<tr>
<td>1112</td>
<td>0.450000</td>
<td>0.244737</td>
<td>0.305263</td>
</tr>
<tr>
<td>1213</td>
<td>0.433862</td>
<td>0.285714</td>
<td>0.280423</td>
</tr>
<tr>
<td>1314</td>
<td>0.472973</td>
<td>0.208108</td>
<td>0.318919</td>
</tr>
<tr>
<td>1415</td>
<td>0.453826</td>
<td>0.245383</td>
<td>0.300792</td>
</tr>
<tr>
<td>1516</td>
<td>0.414248</td>
<td>0.282322</td>
<td>0.303430</td>
</tr>
<tr>
<td>1617</td>
<td>0.492105</td>
<td>0.221053</td>
<td>0.286842</td>
</tr>
<tr>
<td>1718</td>
<td>0.455263</td>
<td>0.260526</td>
<td>0.284211</td>
</tr>
<tr>
<td>1819</td>
<td>0.466667</td>
<td>0.200000</td>
<td>0.333333</td>
</tr>
</tbody>
</table>
<h3 id="findings">Findings</h3>
<p>As we can see, winrates across home team wins, draws and away team wins are very consistent. It seems that the home team wins around 46-47% of the time, the draw happens about 25% of the time, and the away team wins about 27% of the time. Let's plot this DataFrame so that we can see the trend more easily.</p>
<pre><code class="language-python"># Set the style
plt.style.use('ggplot')

fig = plt.figure()
ax = fig.add_subplot(111)

home_line = ax.plot(win_rates.homeWin, label='Home Win Rate')
away_line = ax.plot(win_rates.awayWin, label='Away Win Rate')
draw_line = ax.plot(win_rates.draw, label='Draw Win Rate')
ax.set_xlabel(&quot;season&quot;)
ax.set_ylabel(&quot;Win Rate&quot;)
plt.title(&quot;Win Rates&quot;, fontsize=16)

# Add the legend locations
home_legend = plt.legend(handles=home_line, loc='upper right', bbox_to_anchor=(1, 1))
ax = plt.gca().add_artist(home_legend)
away_legend = plt.legend(handles=away_line, loc='center right', bbox_to_anchor=(0.95, 0.4))
ax = plt.gca().add_artist(away_legend)
draw_legend = plt.legend(handles=draw_line, loc='center right', bbox_to_anchor=(0.95, 0.06))
</code></pre>
<p><img alt="png" src="../img/output_10_0.png" /></p>
<p>As we can see, the winrates are relatively stable each season, except for in 14/15 when the home win rate drops dramatically.</p>
<p>Out of interest, let's also have a look at which team has the best home ground advantage. Let's define HGA as home win rate - away win rate. And then plot some of the big clubs' HGA against each other.</p>
<pre><code class="language-python">home_win_rates = \
(df.groupby(['HomeTeam'])
    .homeWin
    .mean())

away_win_rates = \
(df.groupby(['AwayTeam'])
    .awayWin
    .mean())

hga = (home_win_rates - away_win_rates).reset_index().rename(columns={0: 'HGA'}).sort_values(by='HGA', ascending=False)
</code></pre>
<pre><code class="language-python">hga.head(10)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>HomeTeam</th>
<th>HGA</th>
</tr>
</thead>
<tbody>
<tr>
<td>15</td>
<td>Fulham</td>
<td>0.315573</td>
</tr>
<tr>
<td>7</td>
<td>Brighton</td>
<td>0.304762</td>
</tr>
<tr>
<td>20</td>
<td>Man City</td>
<td>0.244980</td>
</tr>
<tr>
<td>14</td>
<td>Everton</td>
<td>0.241935</td>
</tr>
<tr>
<td>30</td>
<td>Stoke</td>
<td>0.241131</td>
</tr>
<tr>
<td>10</td>
<td>Charlton</td>
<td>0.236842</td>
</tr>
<tr>
<td>0</td>
<td>Arsenal</td>
<td>0.236140</td>
</tr>
<tr>
<td>27</td>
<td>Reading</td>
<td>0.234962</td>
</tr>
<tr>
<td>33</td>
<td>Tottenham</td>
<td>0.220207</td>
</tr>
<tr>
<td>21</td>
<td>Man United</td>
<td>0.215620</td>
</tr>
</tbody>
</table>
<p>So the club with the best HGA is Fulham - interesting. This is most likely because Fulham have won 100% of home games in 2018 so far which is skewing the mean. Let's see how the HGA for some of the big clubs based compare over seasons.</p>
<pre><code class="language-python">big_clubs = ['Liverpool', 'Man City', 'Man United', 'Chelsea', 'Arsenal']
home_win_rates_5 = df[df.HomeTeam.isin(big_clubs)].groupby(['HomeTeam', 'season']).homeWin.mean()
away_win_rates_5 = df[df.AwayTeam.isin(big_clubs)].groupby(['AwayTeam', 'season']).awayWin.mean()

hga_top_5 = home_win_rates_5 - away_win_rates_5

hga_top_5.unstack(level=0)
</code></pre>
<table>
<thead>
<tr>
<th>HomeTeam</th>
<th>Arsenal</th>
<th>Chelsea</th>
<th>Liverpool</th>
<th>Man City</th>
<th>Man United</th>
</tr>
</thead>
<tbody>
<tr>
<td>season</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>0506</td>
<td>0.421053</td>
<td>0.368421</td>
<td>0.263158</td>
<td>0.263158</td>
<td>0.052632</td>
</tr>
<tr>
<td>0607</td>
<td>0.263158</td>
<td>0.000000</td>
<td>0.421053</td>
<td>-0.052632</td>
<td>0.105263</td>
</tr>
<tr>
<td>0708</td>
<td>0.210526</td>
<td>-0.052632</td>
<td>0.157895</td>
<td>0.368421</td>
<td>0.368421</td>
</tr>
<tr>
<td>0809</td>
<td>0.105263</td>
<td>-0.157895</td>
<td>-0.052632</td>
<td>0.578947</td>
<td>0.210526</td>
</tr>
<tr>
<td>0910</td>
<td>0.368421</td>
<td>0.368421</td>
<td>0.421053</td>
<td>0.315789</td>
<td>0.263158</td>
</tr>
<tr>
<td>1011</td>
<td>0.157895</td>
<td>0.368421</td>
<td>0.368421</td>
<td>0.263158</td>
<td>0.684211</td>
</tr>
<tr>
<td>1112</td>
<td>0.157895</td>
<td>0.315789</td>
<td>-0.105263</td>
<td>0.421053</td>
<td>0.105263</td>
</tr>
<tr>
<td>1213</td>
<td>0.052632</td>
<td>0.105263</td>
<td>0.105263</td>
<td>0.248538</td>
<td>0.201754</td>
</tr>
<tr>
<td>1314</td>
<td>0.143275</td>
<td>0.251462</td>
<td>0.307018</td>
<td>0.362573</td>
<td>-0.026316</td>
</tr>
<tr>
<td>1415</td>
<td>0.131579</td>
<td>0.210526</td>
<td>0.105263</td>
<td>0.210526</td>
<td>0.421053</td>
</tr>
<tr>
<td>1516</td>
<td>0.210526</td>
<td>-0.105263</td>
<td>0.000000</td>
<td>0.263158</td>
<td>0.263158</td>
</tr>
<tr>
<td>1617</td>
<td>0.263158</td>
<td>0.210526</td>
<td>0.105263</td>
<td>-0.052632</td>
<td>-0.105263</td>
</tr>
<tr>
<td>1718</td>
<td>0.578947</td>
<td>0.052632</td>
<td>0.157895</td>
<td>0.000000</td>
<td>0.263158</td>
</tr>
<tr>
<td>1819</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.500000</td>
</tr>
</tbody>
</table>
<p>Now let's plot it.</p>
<pre><code class="language-python">sns.lineplot(x='season', y='HGA', hue='team', data=hga_top_5.reset_index().rename(columns={0: 'HGA', 'HomeTeam': 'team'}))
plt.legend(loc='lower center', ncol=6, bbox_to_anchor=(0.45, -0.2))
plt.title(&quot;HGA Among the top 5 clubs&quot;, fontsize=14)
plt.show()
</code></pre>
<p><img alt="png" src="../img/output_17_0.png" /></p>
<p>The results here seem to be quite erratic, although it seems that Arsenal consistently has a HGA above 0.</p>
<p>Let's now look at the distributions of each of our columns. The odds columns are likely to be highly skewed, so we may have to account for this later.</p>
<pre><code class="language-python">for col in df.select_dtypes('number').columns:
    sns.distplot(df[col])
    plt.title(f&quot;Distribution for {col}&quot;)
    plt.show()
</code></pre>
<p><img alt="png" src="../img/output_20_0.png" /></p>
<p><img alt="png" src="../img/output_20_1.png" /></p>
<p><img alt="png" src="../img/output_20_2.png" /></p>
<p><img alt="png" src="../img/output_20_3.png" /></p>
<p><img alt="png" src="../img/output_20_4.png" /></p>
<p><img alt="png" src="../img/output_20_5.png" /></p>
<p><img alt="png" src="../img/output_20_6.png" /></p>
<p><img alt="png" src="../img/output_20_7.png" /></p>
<p><img alt="png" src="../img/output_20_8.png" /></p>
<p><img alt="png" src="../img/output_20_9.png" /></p>
<p><img alt="png" src="../img/output_20_10.png" /></p>
<p><img alt="png" src="../img/output_20_11.png" /></p>
<p><img alt="png" src="../img/output_20_12.png" /></p>
<p><img alt="png" src="../img/output_20_13.png" /></p>
<p><img alt="png" src="../img/output_20_14.png" /></p>
<p><img alt="png" src="../img/output_20_15.png" /></p>
<p><img alt="png" src="../img/output_20_16.png" /></p>
<p><img alt="png" src="../img/output_20_17.png" /></p>
<p><img alt="png" src="../img/output_20_18.png" /></p>
<p><img alt="png" src="../img/output_20_19.png" /></p>
<p><img alt="png" src="../img/output_20_20.png" /></p>
<p><img alt="png" src="../img/output_20_21.png" /></p>
<p><img alt="png" src="../img/output_20_22.png" /></p>
<p><img alt="png" src="../img/output_20_23.png" /></p>
<p><img alt="png" src="../img/output_20_24.png" /></p>
<p><img alt="png" src="../img/output_20_25.png" /></p>
<p><img alt="png" src="../img/output_20_26.png" /></p>
<p><img alt="png" src="../img/output_20_27.png" /></p>
<p><img alt="png" src="../img/output_20_28.png" /></p>
<p><img alt="png" src="../img/output_20_29.png" /></p>
<p><img alt="png" src="../img/output_20_30.png" /></p>
<p><img alt="png" src="../img/output_20_31.png" /></p>
<p><img alt="png" src="../img/output_20_32.png" /></p>
<p><img alt="png" src="../img/output_20_33.png" /></p>
<p><img alt="png" src="../img/output_20_34.png" /></p>
<p><img alt="png" src="../img/output_20_35.png" /></p>
<p><img alt="png" src="../img/output_20_36.png" /></p>
<p><img alt="png" src="../img/output_20_37.png" /></p>
<p><img alt="png" src="../img/output_20_38.png" /></p>
<p><img alt="png" src="../img/output_20_39.png" /></p>
<p><img alt="png" src="../img/output_20_40.png" /></p>
<p><img alt="png" src="../img/output_20_41.png" /></p>
<p><img alt="png" src="../img/output_20_42.png" /></p>
<p><img alt="png" src="../img/output_20_43.png" /></p>
<p><img alt="png" src="../img/output_20_44.png" /></p>
<p><img alt="png" src="../img/output_20_45.png" /></p>
<p><img alt="png" src="../img/output_20_46.png" /></p>
<p><img alt="png" src="../img/output_20_47.png" /></p>
<p><img alt="png" src="../img/output_20_48.png" /></p>
<p><img alt="png" src="../img/output_20_49.png" /></p>
<p><img alt="png" src="../img/output_20_50.png" /></p>
<p><img alt="png" src="../img/output_20_51.png" /></p>
<p><img alt="png" src="../img/output_20_52.png" /></p>
<hr />
<h2 id="exploring-referee-home-ground-bias">Exploring Referee Home Ground Bias</h2>
<p>What may be of interest is whether certain referees are correlated with the home team winning more often. Let's explore referee home ground bias for referees for the top 10 Referees based on games.</p>
<pre><code class="language-python">print('Overall Home Win Rate: {:.4}%'.format(df.homeWin.mean() * 100))

# Get the top 10 refs based on games
top_10_refs = df.Referee.value_counts().head(10).index

df[df.Referee.isin(top_10_refs)].groupby('Referee').homeWin.mean().sort_values(ascending=False)
</code></pre>
<pre><code>Overall Home Win Rate: 46.55%

Referee
L Mason          0.510373
C Foy            0.500000
M Clattenburg    0.480000
M Jones          0.475248
P Dowd           0.469880
M Atkinson       0.469565
M Oliver         0.466019
H Webb           0.456604
A Marriner       0.455516
M Dean           0.442049
Name: homeWin, dtype: float64
</code></pre>
<p>It seems that L Mason may be the most influenced by the home crowd. Whilst the overall home win rate is 46.5%, the home win rate when he is the Referee is 51%. However it should be noted that this doesn't mean that he causes the win through bias. It could just be that he referees the best clubs, so naturally their home win rate is high.</p>
<hr />
<h2 id="variable-correlation-with-margin">Variable Correlation With Margin</h2>
<p>Let's now explore different variables' relationships with margin. First, we'll create a margin column, then we will pick a few different variables to look at the correlations amongst each other, using a correlation heatmap.</p>
<pre><code class="language-python">df['margin'] = df['FTHG'] - df['FTAG']
</code></pre>
<pre><code class="language-python">stat_cols = ['AC', 'AF', 'AR', 'AS', 'AST', 'AY', 'HC', 'HF', 'HR', 'HS', 'HST', 'HTR', 'HY', 'margin']

stat_correlations = df[stat_cols].corr()
stat_correlations['margin'].sort_values()

    AST      -0.345703
    AS       -0.298665
    HY       -0.153806
    HR       -0.129393
    AC       -0.073204
    HF       -0.067469
    AF        0.005474
    AY        0.013746
    HC        0.067433
    AR        0.103528
    HS        0.275847
    HST       0.367591
    margin    1.000000
    Name: margin, dtype: float64
</code></pre>
<p>Unsurprisingly, Home Shots on Target correlate the most with Margin, and Away Reds is also high. What is surprising is that Home Yellows has quite a strong negative correlation with margin - this may be because players will play more aggresively when they are losing to try and get the lead back, and hence receive more yellow cards.</p>
<p>Let's now look at the heatmap between variables.</p>
<pre><code class="language-python">sns.heatmap(stat_correlations, annot=True, annot_kws={'size': 10})
    &lt;matplotlib.axes._subplots.AxesSubplot at 0x220a4227048&gt;
</code></pre>
<p><img alt="png" src="../img/output_28_1.png" /></p>
<hr />
<h2 id="analysing-features">Analysing Features</h2>
<p>What we are really interested in, is how our features (creating in the next tutorial), correlate with winning. We will skip ahead here and use a function to create our features for us, and then examine how the moving averages/different features correlate with winning.</p>
<pre><code class="language-python"># Create a cleaned df of all of our data
pre_features_df = create_df('data/epl_data.csv')

# Create our features
features = create_feature_df(pre_features_df)
    Creating all games feature DataFrame

    C:\Users\wardj\Documents\Betfair Public Github\predictive-models\epl\data_preparation_functions.py:419: RuntimeWarning: invalid value encountered in double_scalars
      .pipe(lambda df: (df.eloAgainst * df[goalsForOrAgainstCol]).sum() / df.eloAgainst.sum()))

    Creating stats feature DataFrame
    Creating odds feature DataFrame
    Creating market values feature DataFrame
    Filling NAs
    Merging stats, odds and market values into one features DataFrame
    Complete.
</code></pre>
<pre><code class="language-python">features = (pre_features_df.assign(margin=lambda df: df.FTHG - df.FTAG)
                           .loc[:, ['gameId', 'margin']]
                           .pipe(pd.merge, features, on=['gameId']))
</code></pre>
<pre><code class="language-python">features.corr().margin.sort_values(ascending=False)[:20]

    margin                     1.000000
    f_awayOdds                 0.413893
    f_totalMktH%               0.330420
    f_defMktH%                 0.325392
    f_eloAgainstAway           0.317853
    f_eloForHome               0.317853
    f_midMktH%                 0.316080
    f_attMktH%                 0.312262
    f_sizeOfHandicapAway       0.301667
    f_goalsForHome             0.298930
    f_wtEloGoalsForHome        0.297157
    f_shotsForHome             0.286239
    f_cornersForHome           0.279917
    f_gkMktH%                  0.274732
    f_homeWinPc38Away          0.271326
    f_homeWinPc38Home          0.271326
    f_wtEloGoalsAgainstAway    0.269663
    f_goalsAgainstAway         0.258418
    f_cornersAgainstAway       0.257148
    f_drawOdds                 0.256807
    Name: margin, dtype: float64
</code></pre>
<p>As we can see away odds is most highly correlated to margin. This makes sense, as odds generally have most/all information included in the price. What is interesting is that elo seems to also be highly correlated, which is good news for our elo model that we made. Similarly, weighted goals and the the value of the defence relative to other teams ('defMktH%' etc.) is strongly correlated to margin.</p>
<hr />
<h1 id="02-data-preparation-feature-engineering">02. Data Preparation &amp; Feature Engineering</h1>
<p>Welcome to the second part of this Machine Learning Walkthrough. This tutorial will focus on data preparation and feature creation, before we dive into modelling in the <a href="/modelling/EPLmodelPart3">next tutorial</a>.</p>
<p>Specifically, this tutorial will cover a few things:</p>
<ol>
<li>Data wrangling specifically for sport</li>
<li>Feature creation - focussing on commonly used features in sports modelling, such as exponential moving averages</li>
<li>Using functions to modularise the data preparation process</li>
</ol>
<hr />
<h2 id="data-wrangling">Data Wrangling</h2>
<p>We will begin by utilising functions we have defined in our data_preparation_functions script to wrangle our data into a format that can be consumed by Machine Learning algorithms.</p>
<p>A typical issue faced by aspect of modelling sport is the issue of Machine Learning algorithms requiring all features for the teams playing to be on the same row of a table, whereas when we actual calculate these features, we usually require the teams to be on separate rows as it makes it a lot easier to calculate typical features, such as <a href="https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average">expontentially weighted moving averages</a>. We will explore this issue and show how we deal with issues like these.</p>
<pre><code class="language-python"># Import libraries
from data_preparation_functions import *
from sklearn.metrics import log_loss
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold, cross_val_score
import matplotlib.pyplot as plt
pd.set_option('display.max_columns', 100)
</code></pre>
<p>We have created some functions which prepare the data for you. For thoroughly commented explanation of how the functions work, read through the data_preparation_functions.py script along side this walkthrough.</p>
<p>Essentially, each functions wrangles the data through a similar process. It first reads in the data from a csv file, then converts the columns to datatypes that we can work with, such as converting the Date column to a datetime data type. It then adds a Game ID column, so each game is easily identifiable and joined on. We then assign the DataFrame some other columns which may be useful, such as 'Year', 'Result' and 'homeWin'. Finally, we drop redundant column and return the DataFrame.</p>
<p>Let us now create six different DataFrames, which we will use to create features. Later, we will join these features back into one main feature DataFrame.</p>
<h3 id="create-6-distinct-dataframes">Create 6 distinct DataFrames</h3>
<pre><code class="language-python"># This table includes all of our data in one big DataFrame
df = create_df('data/epl_data.csv')
df.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>AC</th>
<th>AF</th>
<th>AR</th>
<th>AS</th>
<th>AST</th>
<th>AY</th>
<th>AwayTeam</th>
<th>B365A</th>
<th>B365D</th>
<th>B365H</th>
<th>BWA</th>
<th>BWD</th>
<th>BWH</th>
<th>Bb1X2</th>
<th>BbAH</th>
<th>BbAHh</th>
<th>BbAv&lt;2.5</th>
<th>BbAv&gt;2.5</th>
<th>BbAvA</th>
<th>BbAvAHA</th>
<th>BbAvAHH</th>
<th>BbAvD</th>
<th>BbAvH</th>
<th>BbMx&lt;2.5</th>
<th>BbMx&gt;2.5</th>
<th>BbMxA</th>
<th>BbMxAHA</th>
<th>BbMxAHH</th>
<th>BbMxD</th>
<th>BbMxH</th>
<th>BbOU</th>
<th>Date</th>
<th>Day</th>
<th>Div</th>
<th>FTAG</th>
<th>FTHG</th>
<th>FTR</th>
<th>HC</th>
<th>HF</th>
<th>HR</th>
<th>HS</th>
<th>HST</th>
<th>HTAG</th>
<th>HTHG</th>
<th>HTR</th>
<th>HY</th>
<th>HomeTeam</th>
<th>IWA</th>
<th>IWD</th>
<th>IWH</th>
<th>LBA</th>
<th>LBD</th>
<th>LBH</th>
<th>Month</th>
<th>Referee</th>
<th>VCA</th>
<th>VCD</th>
<th>VCH</th>
<th>Year</th>
<th>season</th>
<th>gameId</th>
<th>homeWin</th>
<th>awayWin</th>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>6.0</td>
<td>14.0</td>
<td>1.0</td>
<td>11.0</td>
<td>5.0</td>
<td>1.0</td>
<td>Blackburn</td>
<td>2.75</td>
<td>3.20</td>
<td>2.5</td>
<td>2.90</td>
<td>3.30</td>
<td>2.20</td>
<td>55.0</td>
<td>20.0</td>
<td>0.00</td>
<td>1.71</td>
<td>2.02</td>
<td>2.74</td>
<td>2.04</td>
<td>1.82</td>
<td>3.16</td>
<td>2.40</td>
<td>1.80</td>
<td>2.25</td>
<td>2.9</td>
<td>2.08</td>
<td>1.86</td>
<td>3.35</td>
<td>2.60</td>
<td>35.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>1.0</td>
<td>3.0</td>
<td>H</td>
<td>2.0</td>
<td>11.0</td>
<td>0.0</td>
<td>13.0</td>
<td>5.0</td>
<td>1.0</td>
<td>0.0</td>
<td>A</td>
<td>0.0</td>
<td>West Ham</td>
<td>2.7</td>
<td>3.0</td>
<td>2.3</td>
<td>2.75</td>
<td>3.0</td>
<td>2.38</td>
<td>8</td>
<td>A Wiley</td>
<td>2.75</td>
<td>3.25</td>
<td>2.4</td>
<td>2005</td>
<td>0506</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>home</td>
</tr>
<tr>
<td>1</td>
<td>8.0</td>
<td>16.0</td>
<td>0.0</td>
<td>13.0</td>
<td>6.0</td>
<td>2.0</td>
<td>Bolton</td>
<td>3.00</td>
<td>3.25</td>
<td>2.3</td>
<td>3.15</td>
<td>3.25</td>
<td>2.10</td>
<td>56.0</td>
<td>22.0</td>
<td>-0.25</td>
<td>1.70</td>
<td>2.01</td>
<td>3.05</td>
<td>1.84</td>
<td>2.01</td>
<td>3.16</td>
<td>2.20</td>
<td>1.87</td>
<td>2.20</td>
<td>3.4</td>
<td>1.92</td>
<td>2.10</td>
<td>3.30</td>
<td>2.40</td>
<td>36.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>2.0</td>
<td>2.0</td>
<td>D</td>
<td>7.0</td>
<td>14.0</td>
<td>0.0</td>
<td>3.0</td>
<td>2.0</td>
<td>2.0</td>
<td>2.0</td>
<td>D</td>
<td>0.0</td>
<td>Aston Villa</td>
<td>3.1</td>
<td>3.0</td>
<td>2.1</td>
<td>3.20</td>
<td>3.0</td>
<td>2.10</td>
<td>8</td>
<td>M Riley</td>
<td>3.10</td>
<td>3.25</td>
<td>2.2</td>
<td>2005</td>
<td>0506</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>draw</td>
</tr>
<tr>
<td>2</td>
<td>6.0</td>
<td>14.0</td>
<td>0.0</td>
<td>12.0</td>
<td>5.0</td>
<td>1.0</td>
<td>Man United</td>
<td>1.72</td>
<td>3.40</td>
<td>5.0</td>
<td>1.75</td>
<td>3.35</td>
<td>4.35</td>
<td>56.0</td>
<td>23.0</td>
<td>0.75</td>
<td>1.79</td>
<td>1.93</td>
<td>1.69</td>
<td>1.86</td>
<td>2.00</td>
<td>3.36</td>
<td>4.69</td>
<td>1.87</td>
<td>2.10</td>
<td>1.8</td>
<td>1.93</td>
<td>2.05</td>
<td>3.70</td>
<td>5.65</td>
<td>36.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>2.0</td>
<td>0.0</td>
<td>A</td>
<td>8.0</td>
<td>15.0</td>
<td>0.0</td>
<td>10.0</td>
<td>5.0</td>
<td>1.0</td>
<td>0.0</td>
<td>A</td>
<td>3.0</td>
<td>Everton</td>
<td>1.8</td>
<td>3.1</td>
<td>3.8</td>
<td>1.83</td>
<td>3.2</td>
<td>3.75</td>
<td>8</td>
<td>G Poll</td>
<td>1.80</td>
<td>3.30</td>
<td>4.5</td>
<td>2005</td>
<td>0506</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>away</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># This includes only the typical soccer stats, like home corners, home shots on target etc.
stats = create_stats_df('data/epl_data.csv')
stats.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>FTHG</th>
<th>FTAG</th>
<th>HTHG</th>
<th>HTAG</th>
<th>HS</th>
<th>AS</th>
<th>HST</th>
<th>AST</th>
<th>HF</th>
<th>AF</th>
<th>HC</th>
<th>AC</th>
<th>HY</th>
<th>AY</th>
<th>HR</th>
<th>AR</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>West Ham</td>
<td>Blackburn</td>
<td>3.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
<td>13.0</td>
<td>11.0</td>
<td>5.0</td>
<td>5.0</td>
<td>11.0</td>
<td>14.0</td>
<td>2.0</td>
<td>6.0</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>Aston Villa</td>
<td>Bolton</td>
<td>2.0</td>
<td>2.0</td>
<td>2.0</td>
<td>2.0</td>
<td>3.0</td>
<td>13.0</td>
<td>2.0</td>
<td>6.0</td>
<td>14.0</td>
<td>16.0</td>
<td>7.0</td>
<td>8.0</td>
<td>0.0</td>
<td>2.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>Everton</td>
<td>Man United</td>
<td>0.0</td>
<td>2.0</td>
<td>0.0</td>
<td>1.0</td>
<td>10.0</td>
<td>12.0</td>
<td>5.0</td>
<td>5.0</td>
<td>15.0</td>
<td>14.0</td>
<td>8.0</td>
<td>6.0</td>
<td>3.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># This includes all of our betting related data, such as win/draw/lose odds, asian handicaps etc.
betting = create_betting_df('data/epl_data.csv')
betting.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>B365A</th>
<th>B365D</th>
<th>B365H</th>
<th>BWA</th>
<th>BWD</th>
<th>BWH</th>
<th>Bb1X2</th>
<th>BbAH</th>
<th>BbAHh</th>
<th>BbAv&lt;2.5</th>
<th>BbAv&gt;2.5</th>
<th>BbAvA</th>
<th>BbAvAHA</th>
<th>BbAvAHH</th>
<th>BbAvD</th>
<th>BbAvH</th>
<th>BbMx&lt;2.5</th>
<th>BbMx&gt;2.5</th>
<th>BbMxA</th>
<th>BbMxAHA</th>
<th>BbMxAHH</th>
<th>BbMxD</th>
<th>BbMxH</th>
<th>BbOU</th>
<th>Day</th>
<th>Div</th>
<th>IWA</th>
<th>IWD</th>
<th>IWH</th>
<th>LBA</th>
<th>LBD</th>
<th>LBH</th>
<th>Month</th>
<th>VCA</th>
<th>VCD</th>
<th>VCH</th>
<th>Year</th>
<th>homeWin</th>
<th>awayWin</th>
<th>result</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>gameId</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2.75</td>
<td>3.20</td>
<td>2.5</td>
<td>2.90</td>
<td>3.30</td>
<td>2.20</td>
<td>55.0</td>
<td>20.0</td>
<td>0.00</td>
<td>1.71</td>
<td>2.02</td>
<td>2.74</td>
<td>2.04</td>
<td>1.82</td>
<td>3.16</td>
<td>2.40</td>
<td>1.80</td>
<td>2.25</td>
<td>2.9</td>
<td>2.08</td>
<td>1.86</td>
<td>3.35</td>
<td>2.60</td>
<td>35.0</td>
<td>13</td>
<td>E0</td>
<td>2.7</td>
<td>3.0</td>
<td>2.3</td>
<td>2.75</td>
<td>3.0</td>
<td>2.38</td>
<td>8</td>
<td>2.75</td>
<td>3.25</td>
<td>2.4</td>
<td>2005</td>
<td>1</td>
<td>0</td>
<td>home</td>
<td>West Ham</td>
<td>Blackburn</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>3.00</td>
<td>3.25</td>
<td>2.3</td>
<td>3.15</td>
<td>3.25</td>
<td>2.10</td>
<td>56.0</td>
<td>22.0</td>
<td>-0.25</td>
<td>1.70</td>
<td>2.01</td>
<td>3.05</td>
<td>1.84</td>
<td>2.01</td>
<td>3.16</td>
<td>2.20</td>
<td>1.87</td>
<td>2.20</td>
<td>3.4</td>
<td>1.92</td>
<td>2.10</td>
<td>3.30</td>
<td>2.40</td>
<td>36.0</td>
<td>13</td>
<td>E0</td>
<td>3.1</td>
<td>3.0</td>
<td>2.1</td>
<td>3.20</td>
<td>3.0</td>
<td>2.10</td>
<td>8</td>
<td>3.10</td>
<td>3.25</td>
<td>2.2</td>
<td>2005</td>
<td>0</td>
<td>0</td>
<td>draw</td>
<td>Aston Villa</td>
<td>Bolton</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>1.72</td>
<td>3.40</td>
<td>5.0</td>
<td>1.75</td>
<td>3.35</td>
<td>4.35</td>
<td>56.0</td>
<td>23.0</td>
<td>0.75</td>
<td>1.79</td>
<td>1.93</td>
<td>1.69</td>
<td>1.86</td>
<td>2.00</td>
<td>3.36</td>
<td>4.69</td>
<td>1.87</td>
<td>2.10</td>
<td>1.8</td>
<td>1.93</td>
<td>2.05</td>
<td>3.70</td>
<td>5.65</td>
<td>36.0</td>
<td>13</td>
<td>E0</td>
<td>1.8</td>
<td>3.1</td>
<td>3.8</td>
<td>1.83</td>
<td>3.2</td>
<td>3.75</td>
<td>8</td>
<td>1.80</td>
<td>3.30</td>
<td>4.5</td>
<td>2005</td>
<td>0</td>
<td>1</td>
<td>away</td>
<td>Everton</td>
<td>Man United</td>
<td>3</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># This includes all of the team information for each game.
team_info = create_team_info_df('data/epl_data.csv')
team_info.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>Date</th>
<th>season</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>FTR</th>
<th>HTR</th>
<th>Referee</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>2005-08-13</td>
<td>0506</td>
<td>West Ham</td>
<td>Blackburn</td>
<td>H</td>
<td>A</td>
<td>A Wiley</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>2005-08-13</td>
<td>0506</td>
<td>Aston Villa</td>
<td>Bolton</td>
<td>D</td>
<td>D</td>
<td>M Riley</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>2005-08-13</td>
<td>0506</td>
<td>Everton</td>
<td>Man United</td>
<td>A</td>
<td>A</td>
<td>G Poll</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># Whilst the other DataFrames date back to 2005, this DataFrame has data from 2001 to 2005.
historic_games = create_historic_games_df('data/historic_games_pre2005.csv')
historic_games.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Date</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>FTHG</th>
<th>FTAG</th>
<th>gameId</th>
<th>season</th>
<th>homeWin</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2001-08-18</td>
<td>Charlton</td>
<td>Everton</td>
<td>1</td>
<td>2</td>
<td>-1</td>
<td>20012002</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>2001-08-18</td>
<td>Derby</td>
<td>Blackburn</td>
<td>2</td>
<td>1</td>
<td>-1</td>
<td>20012002</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2001-08-18</td>
<td>Leeds</td>
<td>Southampton</td>
<td>2</td>
<td>0</td>
<td>-1</td>
<td>20012002</td>
<td>1</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># This is the historic_games DataFrame appended to the df DataFrame.
all_games = create_all_games_df('data/epl_data.csv', 'data/historic_games_pre2005.csv')
all_games.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Date</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>FTHG</th>
<th>FTAG</th>
<th>gameId</th>
<th>season</th>
<th>homeWin</th>
<th>awayWin</th>
<th>homeWinPc5</th>
<th>homeWinPc38</th>
<th>awayWinPc5</th>
<th>awayWinPc38</th>
<th>gameIdHistoric</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2001-08-18</td>
<td>Charlton</td>
<td>Everton</td>
<td>1.0</td>
<td>2.0</td>
<td>-1</td>
<td>20012002</td>
<td>0</td>
<td>1</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>2001-08-18</td>
<td>Derby</td>
<td>Blackburn</td>
<td>2.0</td>
<td>1.0</td>
<td>-1</td>
<td>20012002</td>
<td>1</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>2001-08-18</td>
<td>Leeds</td>
<td>Southampton</td>
<td>2.0</td>
<td>0.0</td>
<td>-1</td>
<td>20012002</td>
<td>1</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>3</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="feature-creation">Feature Creation</h2>
<p>Now that we have all of our pre-prepared DataFrames, and we know that the data is clean, we can move onto feature creation. As is common practice with sports modelling, we are going to start by creating expontentially weighted moving averages (EMA) as features. To get a better understanding of how EMAs work, read <a href="https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average">here</a>. </p>
<p>In short, an EMA is like a simple moving average, except it weights recent instances more than older instances based on an alpha parameter. The documentation for the pandas (emw method)[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.ewm.html] we will be using states that we can specify alpha in a number of ways. We will specify it in terms of span, where $\alpha = 2 / (span+1), span ≥ 1 $.</p>
<p>Let's first define a function which calculates the exponential moving average for each column in the stats DataFrame. We will then apply this function with other functions we have created, such as create_betting_features_ema, which creates moving averages of betting data.</p>
<p>However, we must first change the structure of our data. Notice that currently each row has both the Home Team's data and the Away Team's data on a single row. This makes it difficult to calculate rolling averages, so we will restructure our DataFrames to ensure each row only contains single team's data. To do this, we will define a function, reate_multiline_df_stats.</p>
<pre><code class="language-python"># Define a function which restructures our DataFrame
def create_multiline_df_stats(old_stats_df):
    # Create a list of columns we want and their mappings to more interpretable names
    home_stats_cols = ['HomeTeam', 'FTHG', 'FTAG', 'HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY',
                       'HR', 'AR']

    away_stats_cols = ['AwayTeam', 'FTAG', 'FTHG', 'HTAG', 'HTHG', 'AS', 'HS', 'AST', 'HST', 'AF', 'HF', 'AC', 'HC', 'AY', 'HY',
                       'AR', 'HR']

    stats_cols_mapping = ['team', 'goalsFor', 'goalsAgainst', 'halfTimeGoalsFor', 'halfTimeGoalsAgainst', 'shotsFor',
                          'shotsAgainst', 'shotsOnTargetFor', 'shotsOnTargetAgainst', 'freesFor', 'freesAgainst', 
                          'cornersFor', 'cornersAgainst', 'yellowsFor', 'yellowsAgainst', 'redsFor', 'redsAgainst']

    # Create a dictionary of the old column names to new column names
    home_mapping = {old_col: new_col for old_col, new_col in zip(home_stats_cols, stats_cols_mapping)}
    away_mapping = {old_col: new_col for old_col, new_col in zip(away_stats_cols, stats_cols_mapping)}

    # Put each team onto an individual row
    multi_line_stats = (old_stats_df[['gameId'] + home_stats_cols] # Filter for only the home team columns
                    .rename(columns=home_mapping) # Rename the columns
                    .assign(homeGame=1) # Assign homeGame=1 so that we can use a general function later
                    .append((old_stats_df[['gameId'] + away_stats_cols]) # Append the away team columns
                            .rename(columns=away_mapping) # Rename the away team columns
                            .assign(homeGame=0), sort=True)
                    .sort_values(by='gameId') # Sort the values
                    .reset_index(drop=True))
    return multi_line_stats
</code></pre>
<pre><code class="language-python"># Define a function which creates an EMA DataFrame from the stats DataFrame
def create_stats_features_ema(stats, span):
    # Create a restructured DataFrames so that we can calculate EMA
    multi_line_stats = create_multiline_df_stats(stats)

    # Create a copy of the DataFrame
    ema_features = multi_line_stats[['gameId', 'team', 'homeGame']].copy()

    # Get the columns that we want to create EMA for
    feature_names = multi_line_stats.drop(columns=['gameId', 'team', 'homeGame']).columns

    # Loop over the features
    for feature_name in feature_names:
        feature_ema = (multi_line_stats.groupby('team')[feature_name] # Calculate the EMA
                                                  .transform(lambda row: row.ewm(span=span, min_periods=2)
                                                             .mean()
                                                             .shift(1))) # Shift the data down 1 so we don't leak data
        ema_features[feature_name] = feature_ema # Add the new feature to the DataFrame
    return ema_features
</code></pre>
<pre><code class="language-python"># Apply the function
stats_features = create_stats_features_ema(stats, span=5)
stats_features.tail()
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>team</th>
<th>homeGame</th>
<th>cornersAgainst</th>
<th>cornersFor</th>
<th>freesAgainst</th>
<th>freesFor</th>
<th>goalsAgainst</th>
<th>goalsFor</th>
<th>halfTimeGoalsAgainst</th>
<th>halfTimeGoalsFor</th>
<th>redsAgainst</th>
<th>redsFor</th>
<th>shotsAgainst</th>
<th>shotsFor</th>
<th>shotsOnTargetAgainst</th>
<th>shotsOnTargetFor</th>
<th>yellowsAgainst</th>
<th>yellowsFor</th>
</tr>
</thead>
<tbody>
<tr>
<td>9903</td>
<td>4952</td>
<td>Newcastle</td>
<td>1</td>
<td>4.301743</td>
<td>4.217300</td>
<td>11.789345</td>
<td>12.245066</td>
<td>0.797647</td>
<td>0.833658</td>
<td>0.644214</td>
<td>0.420832</td>
<td>2.323450e-10</td>
<td>3.333631e-01</td>
<td>11.335147</td>
<td>13.265955</td>
<td>3.211345</td>
<td>4.067990</td>
<td>1.848860</td>
<td>1.627140</td>
</tr>
<tr>
<td>9904</td>
<td>4953</td>
<td>Burnley</td>
<td>0</td>
<td>4.880132</td>
<td>5.165915</td>
<td>13.326703</td>
<td>8.800033</td>
<td>1.945502</td>
<td>0.667042</td>
<td>0.609440</td>
<td>0.529409</td>
<td>3.874405e-03</td>
<td>3.356120e-10</td>
<td>13.129631</td>
<td>10.642381</td>
<td>4.825874</td>
<td>3.970285</td>
<td>0.963527</td>
<td>0.847939</td>
</tr>
<tr>
<td>9905</td>
<td>4953</td>
<td>Fulham</td>
<td>1</td>
<td>4.550255</td>
<td>4.403060</td>
<td>10.188263</td>
<td>8.555589</td>
<td>2.531046</td>
<td>1.003553</td>
<td>0.860573</td>
<td>0.076949</td>
<td>1.002518e-04</td>
<td>8.670776e-03</td>
<td>17.463779</td>
<td>12.278877</td>
<td>8.334019</td>
<td>4.058213</td>
<td>0.980097</td>
<td>1.102974</td>
</tr>
<tr>
<td>9906</td>
<td>4954</td>
<td>Man United</td>
<td>1</td>
<td>3.832573</td>
<td>4.759683</td>
<td>11.640608</td>
<td>10.307946</td>
<td>1.397234</td>
<td>1.495032</td>
<td>1.034251</td>
<td>0.809280</td>
<td>6.683080e-05</td>
<td>1.320468e-05</td>
<td>8.963022</td>
<td>10.198642</td>
<td>3.216957</td>
<td>3.776900</td>
<td>1.040077</td>
<td>1.595650</td>
</tr>
<tr>
<td>9907</td>
<td>4954</td>
<td>Tottenham</td>
<td>0</td>
<td>3.042034</td>
<td>5.160211</td>
<td>8.991460</td>
<td>9.955635</td>
<td>1.332704</td>
<td>2.514789</td>
<td>0.573728</td>
<td>1.010491</td>
<td>4.522878e-08</td>
<td>1.354409e-05</td>
<td>12.543406</td>
<td>17.761004</td>
<td>3.757437</td>
<td>7.279845</td>
<td>1.478976</td>
<td>1.026601</td>
</tr>
</tbody>
</table>
<p>As we can see, we now have averages for each team. Let's create a quick table to see the top 10 teams' goalsFor average EMAs since 2005.</p>
<pre><code class="language-python">pd.DataFrame(stats_features.groupby('team')
                           .goalsFor
                           .mean()
                           .sort_values(ascending=False)[:10])
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>goalsFor</th>
</tr>
</thead>
<tbody>
<tr>
<td>team</td>
<td></td>
</tr>
<tr>
<td>Man United</td>
<td>1.895026</td>
</tr>
<tr>
<td>Chelsea</td>
<td>1.888892</td>
</tr>
<tr>
<td>Arsenal</td>
<td>1.876770</td>
</tr>
<tr>
<td>Man City</td>
<td>1.835863</td>
</tr>
<tr>
<td>Liverpool</td>
<td>1.771125</td>
</tr>
<tr>
<td>Tottenham</td>
<td>1.655063</td>
</tr>
<tr>
<td>Leicester</td>
<td>1.425309</td>
</tr>
<tr>
<td>Blackpool</td>
<td>1.390936</td>
</tr>
<tr>
<td>Everton</td>
<td>1.387110</td>
</tr>
<tr>
<td>Southampton</td>
<td>1.288349</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="optimising-alpha">Optimising Alpha</h2>
<p>It looks like Man United and Chelsea have been two of the best teams since 2005, based on goalsFor. Now that we have our stats features, we may be tempted to move on. However, we have arbitrarily chosen a span of 5. How do we know that this is the best value? We don't. Let's try and optimise this value. </p>
<p>To do this, we will use a simple Logistic Regression model to create probabilistic predictions based on the stats features we created before. We will iterate a range of span values, from say, 3 to 15, and choose the value which produces a model with the lowest log loss, based on cross validation.</p>
<p>To do this, we need to restructure our DataFrame back to how it was before.</p>
<pre><code class="language-python">def restructure_stats_features(stats_features):
    non_features = ['homeGame', 'team', 'gameId']

    stats_features_restructured = (stats_features.query('homeGame == 1')
                                    .rename(columns={col: 'f_' + col + 'Home' for col in stats_features.columns if col not in non_features})
                                    .rename(columns={'team': 'HomeTeam'})
                                    .pipe(pd.merge, (stats_features.query('homeGame == 0')
                                                        .rename(columns={'team': 'AwayTeam'})
                                                        .rename(columns={col: 'f_' + col + 'Away' for col in stats_features.columns 
                                                                         if col not in non_features})), on=['gameId'])
                                    .pipe(pd.merge, df[['gameId', 'result']], on='gameId')
                                    .dropna())
    return stats_features_restructured

restructure_stats_features(stats_features).head()
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>HomeTeam</th>
<th>homeGame_x</th>
<th>f_cornersAgainstHome</th>
<th>f_cornersForHome</th>
<th>f_freesAgainstHome</th>
<th>f_freesForHome</th>
<th>f_goalsAgainstHome</th>
<th>f_goalsForHome</th>
<th>f_halfTimeGoalsAgainstHome</th>
<th>f_halfTimeGoalsForHome</th>
<th>f_redsAgainstHome</th>
<th>f_redsForHome</th>
<th>f_shotsAgainstHome</th>
<th>f_shotsForHome</th>
<th>f_shotsOnTargetAgainstHome</th>
<th>f_shotsOnTargetForHome</th>
<th>f_yellowsAgainstHome</th>
<th>f_yellowsForHome</th>
<th>AwayTeam</th>
<th>homeGame_y</th>
<th>f_cornersAgainstAway</th>
<th>f_cornersForAway</th>
<th>f_freesAgainstAway</th>
<th>f_freesForAway</th>
<th>f_goalsAgainstAway</th>
<th>f_goalsForAway</th>
<th>f_halfTimeGoalsAgainstAway</th>
<th>f_halfTimeGoalsForAway</th>
<th>f_redsAgainstAway</th>
<th>f_redsForAway</th>
<th>f_shotsAgainstAway</th>
<th>f_shotsForAway</th>
<th>f_shotsOnTargetAgainstAway</th>
<th>f_shotsOnTargetForAway</th>
<th>f_yellowsAgainstAway</th>
<th>f_yellowsForAway</th>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>20</td>
<td>21</td>
<td>Birmingham</td>
<td>1</td>
<td>4.8</td>
<td>7.8</td>
<td>12.0</td>
<td>9.4</td>
<td>1.2</td>
<td>0.6</td>
<td>0.6</td>
<td>0.6</td>
<td>0.0</td>
<td>0.0</td>
<td>11.4</td>
<td>8.2</td>
<td>6.4</td>
<td>2.8</td>
<td>1.0</td>
<td>2.6</td>
<td>Middlesbrough</td>
<td>0</td>
<td>3.0</td>
<td>5.6</td>
<td>14.0</td>
<td>12.8</td>
<td>1.2</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.4</td>
<td>17.2</td>
<td>8.8</td>
<td>7.6</td>
<td>2.6</td>
<td>3.0</td>
<td>1.4</td>
<td>away</td>
</tr>
<tr>
<td>21</td>
<td>22</td>
<td>Portsmouth</td>
<td>1</td>
<td>2.6</td>
<td>4.6</td>
<td>21.8</td>
<td>16.6</td>
<td>2.0</td>
<td>0.6</td>
<td>1.0</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>8.0</td>
<td>10.4</td>
<td>3.6</td>
<td>4.0</td>
<td>3.2</td>
<td>1.8</td>
<td>Aston Villa</td>
<td>0</td>
<td>9.8</td>
<td>7.0</td>
<td>14.2</td>
<td>18.2</td>
<td>1.4</td>
<td>0.8</td>
<td>0.8</td>
<td>0.8</td>
<td>0.0</td>
<td>0.0</td>
<td>16.0</td>
<td>3.0</td>
<td>9.6</td>
<td>2.6</td>
<td>2.0</td>
<td>0.6</td>
<td>draw</td>
</tr>
<tr>
<td>22</td>
<td>23</td>
<td>Sunderland</td>
<td>1</td>
<td>5.0</td>
<td>5.0</td>
<td>11.6</td>
<td>18.0</td>
<td>1.8</td>
<td>0.4</td>
<td>1.0</td>
<td>0.4</td>
<td>0.4</td>
<td>0.6</td>
<td>14.6</td>
<td>6.0</td>
<td>5.2</td>
<td>3.2</td>
<td>1.2</td>
<td>2.6</td>
<td>Man City</td>
<td>0</td>
<td>7.8</td>
<td>3.6</td>
<td>8.6</td>
<td>12.4</td>
<td>0.6</td>
<td>1.2</td>
<td>0.6</td>
<td>0.6</td>
<td>0.0</td>
<td>0.0</td>
<td>10.6</td>
<td>11.4</td>
<td>2.4</td>
<td>6.8</td>
<td>3.0</td>
<td>1.4</td>
<td>away</td>
</tr>
<tr>
<td>23</td>
<td>24</td>
<td>Arsenal</td>
<td>1</td>
<td>3.0</td>
<td>7.4</td>
<td>17.0</td>
<td>18.6</td>
<td>0.6</td>
<td>0.8</td>
<td>0.0</td>
<td>0.0</td>
<td>0.4</td>
<td>0.0</td>
<td>6.2</td>
<td>11.4</td>
<td>4.0</td>
<td>6.6</td>
<td>1.6</td>
<td>1.8</td>
<td>Fulham</td>
<td>0</td>
<td>7.2</td>
<td>3.0</td>
<td>20.8</td>
<td>13.2</td>
<td>1.2</td>
<td>0.6</td>
<td>0.6</td>
<td>0.0</td>
<td>0.0</td>
<td>0.0</td>
<td>12.4</td>
<td>10.8</td>
<td>7.0</td>
<td>5.2</td>
<td>2.0</td>
<td>1.6</td>
<td>home</td>
</tr>
<tr>
<td>24</td>
<td>25</td>
<td>Blackburn</td>
<td>1</td>
<td>1.4</td>
<td>7.2</td>
<td>12.8</td>
<td>21.2</td>
<td>1.8</td>
<td>1.6</td>
<td>0.0</td>
<td>1.0</td>
<td>0.0</td>
<td>0.4</td>
<td>10.0</td>
<td>14.0</td>
<td>4.4</td>
<td>7.4</td>
<td>1.2</td>
<td>1.6</td>
<td>Tottenham</td>
<td>0</td>
<td>6.4</td>
<td>3.8</td>
<td>11.2</td>
<td>18.8</td>
<td>0.0</td>
<td>2.0</td>
<td>0.0</td>
<td>0.4</td>
<td>0.0</td>
<td>0.0</td>
<td>11.6</td>
<td>15.2</td>
<td>4.6</td>
<td>7.2</td>
<td>0.6</td>
<td>2.6</td>
<td>draw</td>
</tr>
</tbody>
</table>
<p>Now let's write a function that optimises our span based on log loss of the output of a Logistic Regression model.</p>
<pre><code class="language-python">def optimise_alpha(features):
    le = LabelEncoder()
    y = le.fit_transform(features.result) # Encode the result from away, draw, home win to 0, 1, 2
    X = features[[col for col in features.columns if col.startswith('f_')]] # Only get the features - these all start with f_
    lr = LogisticRegression()

    kfold = StratifiedKFold(n_splits=5)
    ave_cv_score = cross_val_score(lr, X, y, scoring='neg_log_loss', cv=kfold).mean()
    return ave_cv_score
</code></pre>
<pre><code class="language-python">best_score = np.float('inf')
best_span = 0
cv_scores = []

# Iterate over a range of spans
for span in range(1, 120, 3):
    stats_features = create_stats_features_ema(stats, span=span)
    restructured_stats_features = restructure_stats_features(stats_features)
    cv_score = optimise_alpha(restructured_stats_features)
    cv_scores.append(cv_score)

    if cv_score * -1 &lt; best_score:
        best_score = cv_score * -1
        best_span = span
</code></pre>
<pre><code class="language-python">plt.style.use('ggplot')
plt.plot(list(range(1, 120, 3)), (pd.Series(cv_scores)*-1)) # Plot our results

plt.title(&quot;Optimising alpha&quot;)
plt.xlabel(&quot;Span&quot;)
plt.ylabel(&quot;Log Loss&quot;)
plt.show()

print(&quot;Our lowest log loss ({:2f}) occurred at a span of {}&quot;.format(best_score, best_span))
</code></pre>
<p><img alt="png" src="../img/output_20_0_EPL.png" /></p>
<pre><code>Our lowest log loss (0.980835) occurred at a span of 55
</code></pre>
<p>The above method is just an example of how you can optimise hyparameters. Obviously this example has many limitations, such as attempting to optimise each statistic with the same alpha. However, for the rest of these tutorial series we will use this span value.</p>
<p>Now let's create the rest of our features. For thorough explanations and the actual code behind some of the functions used, please refer to the data_preparation_functions.py script.</p>
<hr />
<h2 id="creating-our-features-dataframe">Creating our Features DataFrame</h2>
<p>We will utilise pre-made functions to create all of our features in just a few lines of code.</p>
<p>As part of this process we will create features which include margin weighted elo, an exponential average for asian handicap data, and odds as features.</p>
<p>Our Elo function is essentially the same as the one we created in the AFL tutorial; if you would like to know more about Elo models please read <a href="https://www.betfair.com.au/hub/better-betting/betting-strategies/tennis/tennis-elo-modelling/">this</a> article.</p>
<p>Note that the cell below may take a few minutes to run.</p>
<pre><code class="language-python"># Create feature DataFrames
features_all_games = create_all_games_features(all_games)
</code></pre>
<pre><code>C:\Users\wardj\Documents\Betfair Public Github\predictive-models\epl\data_preparation_functions.py:419: RuntimeWarning: invalid value encountered in double_scalars
  .pipe(lambda df: (df.eloAgainst * df[goalsForOrAgainstCol]).sum() / df.eloAgainst.sum()))
</code></pre>
<p>The features_all_games df includes elo for each team, as well as their win percentage at home and away over the past 5 and 38 games. For more information on how it was calculated, read through the data_preparation_functions script.</p>
<pre><code class="language-python">features_all_games.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Date</th>
<th>awayWin</th>
<th>awayWinPc38</th>
<th>awayWinPc5</th>
<th>eloAgainst</th>
<th>eloFor</th>
<th>gameId</th>
<th>gameIdHistoric</th>
<th>goalsAgainst</th>
<th>goalsFor</th>
<th>homeGame</th>
<th>homeWin</th>
<th>homeWinPc38</th>
<th>homeWinPc5</th>
<th>season</th>
<th>team</th>
<th>wtEloGoalsFor</th>
<th>wtEloGoalsAgainst</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2001-08-18</td>
<td>1</td>
<td>NaN</td>
<td>NaN</td>
<td>1500.0</td>
<td>1500.0</td>
<td>-1</td>
<td>1</td>
<td>2.0</td>
<td>1.0</td>
<td>1</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>20012002</td>
<td>Charlton</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr>
<td>1</td>
<td>2001-08-18</td>
<td>1</td>
<td>NaN</td>
<td>NaN</td>
<td>1500.0</td>
<td>1500.0</td>
<td>-1</td>
<td>1</td>
<td>1.0</td>
<td>2.0</td>
<td>0</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>20012002</td>
<td>Everton</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr>
<td>2</td>
<td>2001-08-18</td>
<td>0</td>
<td>NaN</td>
<td>NaN</td>
<td>1500.0</td>
<td>1500.0</td>
<td>-1</td>
<td>2</td>
<td>1.0</td>
<td>2.0</td>
<td>1</td>
<td>1</td>
<td>NaN</td>
<td>NaN</td>
<td>20012002</td>
<td>Derby</td>
<td>NaN</td>
<td>NaN</td>
</tr>
</tbody>
</table>
<p>The features_stats df includes all the expontential weighted averages for each stat in the stats df.</p>
<pre><code class="language-python"># Create feature stats df
features_stats = create_stats_features_ema(stats, span=best_span)
features_stats.tail(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>team</th>
<th>homeGame</th>
<th>cornersAgainst</th>
<th>cornersFor</th>
<th>freesAgainst</th>
<th>freesFor</th>
<th>goalsAgainst</th>
<th>goalsFor</th>
<th>halfTimeGoalsAgainst</th>
<th>halfTimeGoalsFor</th>
<th>redsAgainst</th>
<th>redsFor</th>
<th>shotsAgainst</th>
<th>shotsFor</th>
<th>shotsOnTargetAgainst</th>
<th>shotsOnTargetFor</th>
<th>yellowsAgainst</th>
<th>yellowsFor</th>
</tr>
</thead>
<tbody>
<tr>
<td>9905</td>
<td>4953</td>
<td>Fulham</td>
<td>1</td>
<td>6.006967</td>
<td>5.045733</td>
<td>10.228997</td>
<td>9.965651</td>
<td>2.147069</td>
<td>1.093550</td>
<td>0.630485</td>
<td>0.364246</td>
<td>0.032937</td>
<td>0.043696</td>
<td>16.510067</td>
<td>11.718122</td>
<td>7.184386</td>
<td>4.645762</td>
<td>1.310424</td>
<td>1.389716</td>
</tr>
<tr>
<td>9906</td>
<td>4954</td>
<td>Man United</td>
<td>1</td>
<td>4.463018</td>
<td>5.461075</td>
<td>11.605712</td>
<td>10.870367</td>
<td>0.843222</td>
<td>1.586308</td>
<td>0.427065</td>
<td>0.730650</td>
<td>0.042588</td>
<td>0.027488</td>
<td>10.865754</td>
<td>13.003121</td>
<td>3.562675</td>
<td>4.626450</td>
<td>1.740735</td>
<td>1.712785</td>
</tr>
<tr>
<td>9907</td>
<td>4954</td>
<td>Tottenham</td>
<td>0</td>
<td>3.868619</td>
<td>6.362901</td>
<td>10.784145</td>
<td>10.140388</td>
<td>0.954928</td>
<td>2.100166</td>
<td>0.439129</td>
<td>0.799968</td>
<td>0.024351</td>
<td>0.026211</td>
<td>9.947515</td>
<td>16.460598</td>
<td>3.370010</td>
<td>6.136120</td>
<td>1.925005</td>
<td>1.364268</td>
</tr>
</tbody>
</table>
<p>The features_odds df includes a moving average of some of the odds data.</p>
<pre><code class="language-python"># Create feature_odds df
features_odds = create_betting_features_ema(betting, span=10)
features_odds.tail(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>team</th>
<th>avAsianHandicapOddsAgainst</th>
<th>avAsianHandicapOddsFor</th>
<th>avgreaterthan2.5</th>
<th>avlessthan2.5</th>
<th>sizeOfHandicap</th>
</tr>
</thead>
<tbody>
<tr>
<td>9905</td>
<td>4953</td>
<td>Fulham</td>
<td>1.884552</td>
<td>1.985978</td>
<td>1.756776</td>
<td>2.128261</td>
<td>0.502253</td>
</tr>
<tr>
<td>9906</td>
<td>4954</td>
<td>Man United</td>
<td>1.871586</td>
<td>2.031787</td>
<td>1.900655</td>
<td>1.963478</td>
<td>-0.942445</td>
</tr>
<tr>
<td>9907</td>
<td>4954</td>
<td>Tottenham</td>
<td>1.947833</td>
<td>1.919607</td>
<td>1.629089</td>
<td>2.383593</td>
<td>-1.235630</td>
</tr>
</tbody>
</table>
<p>The features market values has market values and the % of total market for each position. These values are in millions.</p>
<pre><code class="language-python"># Create feature market values df
features_market_values = create_market_values_features(df) # This creates a df with one game per row
features_market_values.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>gameId</th>
<th>Year</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>defMktValH</th>
<th>attMktValH</th>
<th>gkMktValH</th>
<th>totalMktValH</th>
<th>midMktValH</th>
<th>defMktValA</th>
<th>attMktValA</th>
<th>gkMktValA</th>
<th>totalMktValA</th>
<th>midMktValA</th>
<th>attMktH%</th>
<th>attMktA%</th>
<th>midMktH%</th>
<th>midMktA%</th>
<th>defMktH%</th>
<th>defMktA%</th>
<th>gkMktH%</th>
<th>gkMktA%</th>
<th>totalMktH%</th>
<th>totalMktA%</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>2005</td>
<td>West Ham</td>
<td>Blackburn</td>
<td>16.90</td>
<td>18.50</td>
<td>6.40</td>
<td>46.40</td>
<td>4.60</td>
<td>27.25</td>
<td>13.00</td>
<td>3.25</td>
<td>70.70</td>
<td>27.20</td>
<td>2.252911</td>
<td>1.583126</td>
<td>0.588168</td>
<td>3.477861</td>
<td>2.486940</td>
<td>4.010007</td>
<td>4.524247</td>
<td>2.297469</td>
<td>1.913986</td>
<td>2.916354</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>2005</td>
<td>Aston Villa</td>
<td>Bolton</td>
<td>27.63</td>
<td>31.85</td>
<td>7.60</td>
<td>105.83</td>
<td>38.75</td>
<td>9.60</td>
<td>24.55</td>
<td>8.50</td>
<td>72.40</td>
<td>29.75</td>
<td>3.878659</td>
<td>2.989673</td>
<td>4.954673</td>
<td>3.803910</td>
<td>4.065926</td>
<td>1.412700</td>
<td>5.372543</td>
<td>6.008766</td>
<td>4.365456</td>
<td>2.986478</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>2005</td>
<td>Everton</td>
<td>Man United</td>
<td>44.35</td>
<td>31.38</td>
<td>8.55</td>
<td>109.78</td>
<td>25.50</td>
<td>82.63</td>
<td>114.60</td>
<td>9.25</td>
<td>288.48</td>
<td>82.00</td>
<td>3.821423</td>
<td>13.955867</td>
<td>3.260494</td>
<td>10.484727</td>
<td>6.526378</td>
<td>12.159517</td>
<td>6.044111</td>
<td>6.538951</td>
<td>4.528392</td>
<td>11.899714</td>
</tr>
</tbody>
</table>
<pre><code class="language-python">all_games_cols = ['Date', 'gameId', 'team', 'season', 'homeGame', 'homeWinPc38', 'homeWinPc5', 'awayWinPc38', 'awayWinPc5', 'eloFor', 'eloAgainst', 'wtEloGoalsFor', 'wtEloGoalsAgainst']

# Join the features together
features_multi_line = (features_all_games[all_games_cols]
                                         .pipe(pd.merge, features_stats.drop(columns='homeGame'), on=['gameId', 'team'])
                                         .pipe(pd.merge, features_odds, on=['gameId', 'team']))
</code></pre>
<pre><code class="language-python"># Put each instance on an individual row
features_with_na = put_features_on_one_line(features_multi_line)

market_val_feature_names = ['attMktH%', 'attMktA%', 'midMktH%', 'midMktA%', 'defMktH%', 'defMktA%', 'gkMktH%', 'gkMktA%', 'totalMktH%', 'totalMktA%']

# Merge our team values dataframe to features and result from df
features_with_na = (features_with_na.pipe(pd.merge, (features_market_values[market_val_feature_names + ['gameId']])
                                                      .rename({col: 'f_' + col for col in market_val_feature_names}), on='gameId')
                            .pipe(pd.merge, df[['HomeTeam', 'AwayTeam', 'gameId', 'result', 'B365A', 'B365D', 'B365H']], on=['HomeTeam', 'AwayTeam', 'gameId']))

# Drop NAs from calculating the rolling averages - don't drop Win Pc 38 and Win Pc 5 columns
features = features_with_na.dropna(subset=features_with_na.drop(columns=[col for col in features_with_na.columns if 'WinPc' in col]).columns)

# Fill NAs for the Win Pc columns
features = features.fillna(features.mean())
</code></pre>
<pre><code class="language-python">features.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Date</th>
<th>gameId</th>
<th>HomeTeam</th>
<th>season</th>
<th>homeGame</th>
<th>f_homeWinPc38Home</th>
<th>f_homeWinPc5Home</th>
<th>f_awayWinPc38Home</th>
<th>f_awayWinPc5Home</th>
<th>f_eloForHome</th>
<th>f_eloAgainstHome</th>
<th>f_wtEloGoalsForHome</th>
<th>f_wtEloGoalsAgainstHome</th>
<th>f_cornersAgainstHome</th>
<th>f_cornersForHome</th>
<th>f_freesAgainstHome</th>
<th>f_freesForHome</th>
<th>f_goalsAgainstHome</th>
<th>f_goalsForHome</th>
<th>f_halfTimeGoalsAgainstHome</th>
<th>f_halfTimeGoalsForHome</th>
<th>f_redsAgainstHome</th>
<th>f_redsForHome</th>
<th>f_shotsAgainstHome</th>
<th>f_shotsForHome</th>
<th>f_shotsOnTargetAgainstHome</th>
<th>f_shotsOnTargetForHome</th>
<th>f_yellowsAgainstHome</th>
<th>f_yellowsForHome</th>
<th>f_avAsianHandicapOddsAgainstHome</th>
<th>f_avAsianHandicapOddsForHome</th>
<th>f_avgreaterthan2.5Home</th>
<th>f_avlessthan2.5Home</th>
<th>f_sizeOfHandicapHome</th>
<th>AwayTeam</th>
<th>f_homeWinPc38Away</th>
<th>f_homeWinPc5Away</th>
<th>f_awayWinPc38Away</th>
<th>f_awayWinPc5Away</th>
<th>f_eloForAway</th>
<th>f_eloAgainstAway</th>
<th>f_wtEloGoalsForAway</th>
<th>f_wtEloGoalsAgainstAway</th>
<th>f_cornersAgainstAway</th>
<th>f_cornersForAway</th>
<th>f_freesAgainstAway</th>
<th>f_freesForAway</th>
<th>f_goalsAgainstAway</th>
<th>f_goalsForAway</th>
<th>f_halfTimeGoalsAgainstAway</th>
<th>f_halfTimeGoalsForAway</th>
<th>f_redsAgainstAway</th>
<th>f_redsForAway</th>
<th>f_shotsAgainstAway</th>
<th>f_shotsForAway</th>
<th>f_shotsOnTargetAgainstAway</th>
<th>f_shotsOnTargetForAway</th>
<th>f_yellowsAgainstAway</th>
<th>f_yellowsForAway</th>
<th>f_avAsianHandicapOddsAgainstAway</th>
<th>f_avAsianHandicapOddsForAway</th>
<th>f_avgreaterthan2.5Away</th>
<th>f_avlessthan2.5Away</th>
<th>f_sizeOfHandicapAway</th>
<th>attMktH%</th>
<th>attMktA%</th>
<th>midMktH%</th>
<th>midMktA%</th>
<th>defMktH%</th>
<th>defMktA%</th>
<th>gkMktH%</th>
<th>gkMktA%</th>
<th>totalMktH%</th>
<th>totalMktA%</th>
<th>result</th>
<th>B365A</th>
<th>B365D</th>
<th>B365H</th>
</tr>
</thead>
<tbody>
<tr>
<td>20</td>
<td>2005-08-23</td>
<td>21</td>
<td>Birmingham</td>
<td>0506</td>
<td>1</td>
<td>0.394737</td>
<td>0.4</td>
<td>0.263158</td>
<td>0.2</td>
<td>1478.687038</td>
<td>1492.866048</td>
<td>1.061763</td>
<td>1.260223</td>
<td>4.981818</td>
<td>7.527273</td>
<td>12.000000</td>
<td>9.945455</td>
<td>1.018182</td>
<td>0.509091</td>
<td>0.509091</td>
<td>0.509091</td>
<td>0.000000</td>
<td>0.000000</td>
<td>11.945455</td>
<td>8.018182</td>
<td>6.490909</td>
<td>2.981818</td>
<td>1.000000</td>
<td>2.509091</td>
<td>1.9090</td>
<td>1.9455</td>
<td>2.0510</td>
<td>1.6735</td>
<td>-0.1375</td>
<td>Middlesbrough</td>
<td>0.394737</td>
<td>0.4</td>
<td>0.263158</td>
<td>0.2</td>
<td>1492.866048</td>
<td>1478.687038</td>
<td>1.12994</td>
<td>1.279873</td>
<td>2.545455</td>
<td>5.509091</td>
<td>13.545455</td>
<td>13.436364</td>
<td>1.018182</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.0</td>
<td>0.490909</td>
<td>17.018182</td>
<td>8.072727</td>
<td>7.509091</td>
<td>2.509091</td>
<td>3.0</td>
<td>1.490909</td>
<td>1.9395</td>
<td>1.9095</td>
<td>2.0035</td>
<td>1.7155</td>
<td>0.3875</td>
<td>5.132983</td>
<td>5.260851</td>
<td>3.341048</td>
<td>4.289788</td>
<td>3.502318</td>
<td>4.168935</td>
<td>2.332815</td>
<td>3.216457</td>
<td>3.934396</td>
<td>4.522205</td>
<td>away</td>
<td>2.75</td>
<td>3.2</td>
<td>2.50</td>
</tr>
<tr>
<td>21</td>
<td>2005-08-23</td>
<td>22</td>
<td>Portsmouth</td>
<td>0506</td>
<td>1</td>
<td>0.447368</td>
<td>0.4</td>
<td>0.263158</td>
<td>0.4</td>
<td>1405.968416</td>
<td>1489.229314</td>
<td>1.147101</td>
<td>1.503051</td>
<td>2.509091</td>
<td>4.963636</td>
<td>21.981818</td>
<td>16.054545</td>
<td>2.000000</td>
<td>0.509091</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>8.454545</td>
<td>10.490909</td>
<td>3.963636</td>
<td>4.454545</td>
<td>3.018182</td>
<td>1.527273</td>
<td>1.8965</td>
<td>1.9690</td>
<td>2.0040</td>
<td>1.7005</td>
<td>0.2500</td>
<td>Aston Villa</td>
<td>0.447368</td>
<td>0.4</td>
<td>0.263158</td>
<td>0.4</td>
<td>1489.229314</td>
<td>1405.968416</td>
<td>1.17516</td>
<td>1.263229</td>
<td>9.527273</td>
<td>7.000000</td>
<td>14.472727</td>
<td>17.563636</td>
<td>1.490909</td>
<td>0.981818</td>
<td>0.981818</td>
<td>0.981818</td>
<td>0.0</td>
<td>0.000000</td>
<td>15.545455</td>
<td>3.000000</td>
<td>9.054545</td>
<td>2.509091</td>
<td>2.0</td>
<td>0.509091</td>
<td>1.8565</td>
<td>1.9770</td>
<td>1.8505</td>
<td>1.8485</td>
<td>0.7125</td>
<td>3.738614</td>
<td>3.878659</td>
<td>4.494368</td>
<td>4.954673</td>
<td>2.884262</td>
<td>4.065926</td>
<td>3.746642</td>
<td>5.372543</td>
<td>3.743410</td>
<td>4.365456</td>
<td>draw</td>
<td>2.75</td>
<td>3.2</td>
<td>2.50</td>
</tr>
<tr>
<td>22</td>
<td>2005-08-23</td>
<td>23</td>
<td>Sunderland</td>
<td>0506</td>
<td>1</td>
<td>0.236842</td>
<td>0.0</td>
<td>0.236842</td>
<td>0.4</td>
<td>1277.888970</td>
<td>1552.291880</td>
<td>0.650176</td>
<td>1.543716</td>
<td>5.000000</td>
<td>5.000000</td>
<td>12.418182</td>
<td>17.545455</td>
<td>1.981818</td>
<td>0.490909</td>
<td>1.000000</td>
<td>0.490909</td>
<td>0.490909</td>
<td>0.509091</td>
<td>14.509091</td>
<td>6.909091</td>
<td>5.018182</td>
<td>3.927273</td>
<td>1.018182</td>
<td>2.509091</td>
<td>1.8520</td>
<td>1.9915</td>
<td>1.8535</td>
<td>1.8500</td>
<td>0.7125</td>
<td>Man City</td>
<td>0.236842</td>
<td>0.0</td>
<td>0.236842</td>
<td>0.4</td>
<td>1552.291880</td>
<td>1277.888970</td>
<td>1.28875</td>
<td>1.287367</td>
<td>7.527273</td>
<td>3.509091</td>
<td>8.963636</td>
<td>12.490909</td>
<td>0.509091</td>
<td>1.018182</td>
<td>0.509091</td>
<td>0.509091</td>
<td>0.0</td>
<td>0.000000</td>
<td>10.963636</td>
<td>11.945455</td>
<td>2.490909</td>
<td>6.981818</td>
<td>3.0</td>
<td>1.490909</td>
<td>1.8150</td>
<td>2.0395</td>
<td>2.0060</td>
<td>1.7095</td>
<td>-0.2000</td>
<td>0.706318</td>
<td>3.750792</td>
<td>1.476812</td>
<td>1.070209</td>
<td>2.634096</td>
<td>4.455890</td>
<td>0.777605</td>
<td>4.913050</td>
<td>1.499427</td>
<td>3.151477</td>
<td>away</td>
<td>2.50</td>
<td>3.2</td>
<td>2.75</td>
</tr>
</tbody>
</table>
<p>We now have a features DataFrame ready, with all the feature columns beginning with the "f_". In the next section, we will walk through the modelling process to try and find the best type of model to use.</p>
<hr />
<h1 id="03-model-building-hyperparameter-tuning">03. Model Building &amp; Hyperparameter Tuning</h1>
<p>Welcome to the third part of this Machine Learning Walkthrough. This tutorial will focus on the model building process, including how to tune hyperparameters. In the [next tutorial], we will create weekly predictions based on the model we have created here.</p>
<p>Specifically, this tutorial will cover a few things:</p>
<ol>
<li>Choosing which Machine Learning algorithm to use from a variety of choices</li>
<li>Hyperparameter Tuning</li>
<li>Overfitting/Underfitting</li>
</ol>
<hr />
<h2 id="choosing-an-algorithm">Choosing an Algorithm</h2>
<p>The best way to decide on specific algorithm to use, is to try them all! To do this, we will define a function which we first used in our AFL Predictions tutorial. This will iterate over a number of algorithms and give us a good indication of which algorithms are suited for this dataset and exercise.</p>
<p>Let's first use grab the features we created in the last tutorial. This may take a minute or two to run.</p>
<pre><code class="language-python">## Import libraries
from data_preparation_functions import *
import pandas as pd
import numpy as np
import matplotlib as plt
import seaborn as sns
import warnings
from sklearn import linear_model, tree, discriminant_analysis, naive_bayes, ensemble, gaussian_process
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.metrics import log_loss, confusion_matrix
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', 100)
</code></pre>
<pre><code class="language-python">features = create_feature_df()
    Creating all games feature DataFrame
    Creating stats feature DataFrame
    Creating odds feature DataFrame
    Creating market values feature DataFrame
    Filling NAs
    Merging stats, odds and market values into one features DataFrame
    Complete.
</code></pre>
<p>To start our modelling process, we need to make a training set, a test set and a holdout set. As we are using cross validation, we will make our training set all of the seasons up until 2017/18, and we will use the 2017/18 season as the test set.</p>
<pre><code class="language-python">feature_list = [col for col in features.columns if col.startswith(&quot;f_&quot;)]
betting_features = []

le = LabelEncoder() # Initiate a label encoder to transform the labels 'away', 'draw', 'home' to 0, 1, 2

# Grab all seasons except for 17/18 to use CV with
all_x = features.loc[features.season != '1718', ['gameId'] + feature_list]
all_y = features.loc[features.season != '1718', 'result']
all_y = le.fit_transform(all_y)

# Create our training vector as the seasons except 16/17 and 17/18
train_x = features.loc[~features.season.isin(['1617', '1718']), ['gameId'] + feature_list]
train_y = le.transform(features.loc[~features.season.isin(['1617', '1718']), 'result'])

# Create our holdout vectors as the 16/17 season
holdout_x = features.loc[features.season == '1617', ['gameId'] + feature_list]
holdout_y = le.transform(features.loc[features.season == '1617', 'result'])

# Create our test vectors as the 17/18 season
test_x = features.loc[features.season == '1718', ['gameId'] + feature_list]
test_y = le.transform(features.loc[features.season == '1718', 'result'])
</code></pre>
<pre><code class="language-python"># Create a list of standard classifiers
classifiers = [

    #GLM
    linear_model.LogisticRegressionCV(),

    #Navies Bayes
    naive_bayes.BernoulliNB(),
    naive_bayes.GaussianNB(),

    #Discriminant Analysis
    discriminant_analysis.LinearDiscriminantAnalysis(),
    discriminant_analysis.QuadraticDiscriminantAnalysis(),

    #Ensemble Methods
    ensemble.AdaBoostClassifier(),
    ensemble.BaggingClassifier(),
    ensemble.ExtraTreesClassifier(),
    ensemble.GradientBoostingClassifier(),
    ensemble.RandomForestClassifier(),

    #Gaussian Processes
    gaussian_process.GaussianProcessClassifier(),

    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html
#     xgb.XGBClassifier()    
]
</code></pre>
<pre><code class="language-python">def find_best_algorithms(classifier_list, X, y):
    # This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling
    # Cross validate model with Kfold stratified cross validation
    kfold = StratifiedKFold(n_splits=5)

    # Grab the cross validation scores for each algorithm
    cv_results = [cross_val_score(classifier, X, y, scoring = &quot;neg_log_loss&quot;, cv = kfold) for classifier in classifier_list]
    cv_means = [cv_result.mean() * -1 for cv_result in cv_results]
    cv_std = [cv_result.std() for cv_result in cv_results]
    algorithm_names = [alg.__class__.__name__ for alg in classifiers]

    # Create a DataFrame of all the CV results
    cv_results = pd.DataFrame({
        &quot;Mean Log Loss&quot;: cv_means,
        &quot;Log Loss Std&quot;: cv_std,
        &quot;Algorithm&quot;: algorithm_names
    }).sort_values(by='Mean Log Loss')
    return cv_results
</code></pre>
<pre><code class="language-python">algorithm_results = find_best_algorithms(classifiers, all_x, all_y)
</code></pre>
<pre><code class="language-python">algorithm_results
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Mean Log Loss</th>
<th>Log Loss Std</th>
<th>Algorithm</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0.966540</td>
<td>0.020347</td>
<td>LogisticRegressionCV</td>
</tr>
<tr>
<td>3</td>
<td>0.986679</td>
<td>0.015601</td>
<td>LinearDiscriminantAnalysis</td>
</tr>
<tr>
<td>1</td>
<td>1.015197</td>
<td>0.017466</td>
<td>BernoulliNB</td>
</tr>
<tr>
<td>10</td>
<td>1.098612</td>
<td>0.000000</td>
<td>GaussianProcessClassifier</td>
</tr>
<tr>
<td>5</td>
<td>1.101281</td>
<td>0.044383</td>
<td>AdaBoostClassifier</td>
</tr>
<tr>
<td>8</td>
<td>1.137778</td>
<td>0.153391</td>
<td>GradientBoostingClassifier</td>
</tr>
<tr>
<td>7</td>
<td>2.093981</td>
<td>0.284831</td>
<td>ExtraTreesClassifier</td>
</tr>
<tr>
<td>9</td>
<td>2.095088</td>
<td>0.130367</td>
<td>RandomForestClassifier</td>
</tr>
<tr>
<td>6</td>
<td>2.120571</td>
<td>0.503132</td>
<td>BaggingClassifier</td>
</tr>
<tr>
<td>4</td>
<td>4.065796</td>
<td>1.370119</td>
<td>QuadraticDiscriminantAnalysis</td>
</tr>
<tr>
<td>2</td>
<td>5.284171</td>
<td>0.826991</td>
<td>GaussianNB</td>
</tr>
</tbody>
</table>
<p>We can see that LogisticRegression seems to perform the best out of all the algorithms, and some algorithms have a very high log loss. This is most likely due to overfitting. It would definitely be useful to condense our features down to reduce the dimensionality of the dataset.</p>
<hr />
<h2 id="hyperparameter-tuning">Hyperparameter Tuning</h2>
<p>For now, however, we will use logistic regression. Let's first try and tune a logistic regression model with cross validation. To do this, we will use <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">grid search</a>. Grid search essentially tries out each combination of values and finds the model with the lowest error metric, which in our case is log loss. 'C' in logistic regression determines the amount of regularization. Lower values increase regularization.</p>
<pre><code class="language-python"># Define our parameters to run a grid search over
lr_grid = {
    &quot;C&quot;: [0.0001, 0.01, 0.05, 0.2, 1],
    &quot;solver&quot;: [&quot;newton-cg&quot;, &quot;lbfgs&quot;, &quot;liblinear&quot;]
}

kfold = StratifiedKFold(n_splits=5)

gs = GridSearchCV(LogisticRegression(), param_grid=lr_grid, cv=kfold, scoring='neg_log_loss')
gs.fit(all_x, all_y)
print(&quot;Best log loss: {}&quot;.format(gs.best_score_ *-1))
best_lr_params = gs.best_params_

  Best log loss: 0.9669551970849734
</code></pre>
<hr />
<h2 id="defining-a-baseline">Defining a Baseline</h2>
<p>We should also define a baseline, as we don't really know if our log loss is good or bad. Randomly assigning a 1/3 chance to each selection yields a log loss of log3 = 1.09. However, what we are really interested in, is how our model performs relative to the odds. So let's find the log loss of the odds.</p>
<pre><code class="language-python"># Finding the log loss of the odds
log_loss(all_y, 1 / all_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']])

  0.9590114943474463
</code></pre>
<p>This is good news: our algorithm almost beats the bookies in terms of log loss. It would be great if we could beat this result.</p>
<hr />
<h2 id="analysing-the-errors-made">Analysing the Errors Made</h2>
<p>Now that we have a logistic regression model tuned, let's see what type of errors it made. To do this we will look at the confusion matrix produced when we predict our holdout set.</p>
<pre><code class="language-python">lr = LogisticRegression(**best_lr_params) # Instantiate the model
lr.fit(train_x, train_y) # Fit our model
lr_predict = lr.predict(holdout_x) # Predict the holdout values
</code></pre>
<pre><code class="language-python"># Create a confusion matrix
c_matrix = (pd.DataFrame(confusion_matrix(holdout_y, lr_predict), columns=le.classes_, index=le.classes_)
 .rename_axis('Actual')
 .rename_axis('Predicted', axis='columns'))

c_matrix
</code></pre>
<table>
<thead>
<tr>
<th>Predicted</th>
<th>away</th>
<th>draw</th>
<th>home</th>
</tr>
</thead>
<tbody>
<tr>
<td>Actual</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>away</td>
<td>77</td>
<td>0</td>
<td>32</td>
</tr>
<tr>
<td>draw</td>
<td>26</td>
<td>3</td>
<td>55</td>
</tr>
<tr>
<td>home</td>
<td>33</td>
<td>7</td>
<td>147</td>
</tr>
</tbody>
</table>
<p>As we can see, when we predicted 'away' as the result, we correctly predicted 79 / 109 results, a hit rate of 70.6%. However, when we look at our draw hit rate, we only predicted 6 / 84 correctly, meaning we only had a hit rate of around 8.3%. For a more in depth analysis of our predictions, please skip to the Analysing Predictions &amp; Staking Strategies section of the tutorial.</p>
<p>Before we move on, however, let's use our model to predict the 17/18 season and compare how we went with the odds.</p>
<pre><code class="language-python"># Get test predictions

test_lr = LogisticRegression(**best_lr_params)
test_lr.fit(all_x, all_y)
test_predictions_probs = lr.predict_proba(test_x)
test_predictions = lr.predict(test_x)

test_ll = log_loss(test_y, test_predictions_probs)
test_accuracy = (test_predictions == test_y).mean()

print(&quot;Our predictions for the 2017/18 season have a log loss of: {0:.5f} and an accuracy of: {1:.2f}&quot;.format(test_ll, test_accuracy))
</code></pre>
<pre><code>Our predictions for the 2017/18 season have a log loss of: 0.95767 and an accuracy of: 0.56
</code></pre>
<pre><code class="language-python"># Get accuracy and log loss based on the odds
odds_ll = log_loss(test_y, 1 / test_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']])

odds_predictions = test_x[['f_awayOdds', 'f_drawOdds', 'f_homeOdds']].apply(lambda row: row.idxmin()[2:6], axis=1).values
odds_accuracy = (odds_predictions == le.inverse_transform(test_y)).mean()

print(&quot;Odds predictions for the 2017/18 season have a log loss of: {0:.5f} and an accuracy of: {1:.3f}&quot;.format(odds_ll, odds_accuracy))
</code></pre>
<pre><code>Odds predictions for the 2017/18 season have a log loss of: 0.94635 and an accuracy of: 0.545
</code></pre>
<hr />
<h2 id="results">Results</h2>
<p>There we have it! The odds predicted 54.5% of EPL games correctly in the 2017/18 season, whilst our model predicted 54% correctly. This is a decent result for the first iteration of our model. In future iterations, we could wait a certain number of matches each season and calculate EMAs for on those first n games. This may help the issue of players switching clubs and teams becoming relatively stronger/weaker compared to previous seasons.</p>
<hr />
<h1 id="04-weekly-predictions">04. Weekly Predictions</h1>
<p>Welcome to the third part of this Machine Learning Walkthrough. This tutorial will be a walk through of creating weekly EPL predictions from the basic logistic regression model we built in the previous tutorial. We will then analyse our predictions and create staking strategies in the next tutorial.</p>
<p>Specifically, this tutorial will cover a few things:</p>
<ol>
<li>Obtaining Weekly Odds / Game Info Using Betfair's API</li>
<li>Data Wrangling This Week's Game Info Into Our Feature Set</li>
</ol>
<hr />
<h2 id="obtaining-weekly-odds-game-info-using-betfairs-api">Obtaining Weekly Odds / Game Info Using Betfair's API</h2>
<p>The first thing we need to do to create weekly predictions is get both the games being played this week, as well as match odds from Betfair to be used as features.</p>
<p>To make this process easier, I have created a csv file with the fixture for the 2018/19 season. Let's load that now.</p>
<pre><code class="language-python">## Import libraries
import pandas as pd
from weekly_prediction_functions import *
from data_preparation_functions import *
from sklearn.metrics import log_loss, confusion_matrix
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', 100)
</code></pre>
<pre><code class="language-python">fixture = (pd.read_csv('data/fixture.csv')
              .assign(Date=lambda df: pd.to_datetime(df.Date)))
</code></pre>
<pre><code class="language-python">fixture.head()
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Date</th>
<th>Time (AEST)</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>Venue</th>
<th>TV</th>
<th>Year</th>
<th>round</th>
<th>season</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2018-08-11</td>
<td>5:00 AM</td>
<td>Man United</td>
<td>Leicester</td>
<td>Old Trafford, Manchester</td>
<td>Optus, Fox Sports (delay)</td>
<td>2018</td>
<td>1</td>
<td>1819</td>
</tr>
<tr>
<td>1</td>
<td>2018-08-11</td>
<td>9:30 PM</td>
<td>Newcastle</td>
<td>Tottenham</td>
<td>St.James’ Park, Newcastle</td>
<td>Optus, SBS</td>
<td>2018</td>
<td>1</td>
<td>1819</td>
</tr>
<tr>
<td>2</td>
<td>2018-08-12</td>
<td>12:00 AM</td>
<td>Bournemouth</td>
<td>Cardiff</td>
<td>Vitality Stadium, Bournemouth</td>
<td>Optus</td>
<td>2018</td>
<td>1</td>
<td>1819</td>
</tr>
<tr>
<td>3</td>
<td>2018-08-12</td>
<td>12:00 AM</td>
<td>Fulham</td>
<td>Crystal Palace</td>
<td>Craven Cottage, London</td>
<td>Optus</td>
<td>2018</td>
<td>1</td>
<td>1819</td>
</tr>
<tr>
<td>4</td>
<td>2018-08-12</td>
<td>12:00 AM</td>
<td>Huddersfield</td>
<td>Chelsea</td>
<td>John Smith’s Stadium, Huddersfield</td>
<td>Optus, Fox Sports (delay)</td>
<td>2018</td>
<td>1</td>
<td>1819</td>
</tr>
</tbody>
</table>
<p>Now we are going to connect to the API and retrieve game level information for the next week. To do this, we will use an R script. If you are not familiar with R, don't worry, it is relatively simple to read through. For this, we will run the script weekly_game_info_puller.R. Go ahead and run that script now.</p>
<p>Note that for this step, you will require a Betfair API App Key. If you don't have one, visit <a href="../../api/apiappkey">this page and follow the instructions</a>.</p>
<p>I will upload an updated weekly file, so you can follow along regardless of if you have an App Key or not. Let's load that file in now.</p>
<pre><code class="language-python">game_info = create_game_info_df(&quot;data/weekly_game_info.csv&quot;)
</code></pre>
<pre><code class="language-python">game_info.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>AwayTeam</th>
<th>HomeTeam</th>
<th>awaySelectionId</th>
<th>drawSelectionId</th>
<th>homeSelectionId</th>
<th>draw</th>
<th>marketId</th>
<th>marketStartTime</th>
<th>totalMatched</th>
<th>eventId</th>
<th>eventName</th>
<th>homeOdds</th>
<th>drawOdds</th>
<th>awayOdds</th>
<th>competitionId</th>
<th>Date</th>
<th>localMarketStartTime</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Arsenal</td>
<td>Cardiff</td>
<td>1096</td>
<td>58805</td>
<td>79343</td>
<td>The Draw</td>
<td>1.146897152</td>
<td>2018-09-02 12:30:00</td>
<td>30123.595116</td>
<td>28852020</td>
<td>Cardiff v Arsenal</td>
<td>7.00</td>
<td>4.3</td>
<td>1.62</td>
<td>10932509</td>
<td>2018-09-02</td>
<td>Sun September  2, 10:30PM</td>
</tr>
<tr>
<td>1</td>
<td>Bournemouth</td>
<td>Chelsea</td>
<td>1141</td>
<td>58805</td>
<td>55190</td>
<td>The Draw</td>
<td>1.146875421</td>
<td>2018-09-01 14:00:00</td>
<td>30821.329656</td>
<td>28851426</td>
<td>Chelsea v Bournemouth</td>
<td>1.32</td>
<td>6.8</td>
<td>12.00</td>
<td>10932509</td>
<td>2018-09-01</td>
<td>Sun September  2, 12:00AM</td>
</tr>
<tr>
<td>2</td>
<td>Fulham</td>
<td>Brighton</td>
<td>56764</td>
<td>58805</td>
<td>18567</td>
<td>The Draw</td>
<td>1.146875746</td>
<td>2018-09-01 14:00:00</td>
<td>16594.833096</td>
<td>28851429</td>
<td>Brighton v Fulham</td>
<td>2.36</td>
<td>3.5</td>
<td>3.50</td>
<td>10932509</td>
<td>2018-09-01</td>
<td>Sun September  2, 12:00AM</td>
</tr>
</tbody>
</table>
<p>Finally, we will use the API to grab the weekly odds. This R script is also provided, but I have also included the weekly odds csv for convenience.</p>
<pre><code class="language-python">odds = (pd.read_csv('data/weekly_epl_odds.csv')
           .replace({
                'Man Utd': 'Man United',
                'C Palace': 'Crystal Palace'}))
</code></pre>
<pre><code class="language-python">odds.head(3)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>f_homeOdds</th>
<th>f_drawOdds</th>
<th>f_awayOdds</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Leicester</td>
<td>Liverpool</td>
<td>7.80</td>
<td>5.1</td>
<td>1.48</td>
</tr>
<tr>
<td>1</td>
<td>Brighton</td>
<td>Fulham</td>
<td>2.36</td>
<td>3.5</td>
<td>3.50</td>
</tr>
<tr>
<td>2</td>
<td>Everton</td>
<td>Huddersfield</td>
<td>1.54</td>
<td>4.4</td>
<td>8.20</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="data-wrangling-this-weeks-game-info-into-our-feature-set">Data Wrangling This Week's Game Info Into Our Feature Set</h2>
<p>Now we have the arduous task of wrangling all of this info into a feature set that we can use to predict this week's games. Luckily our functions we created earlier should work if we just append the non-features to our main dataframe.</p>
<pre><code class="language-python">df = create_df('data/epl_data.csv')
</code></pre>
<pre><code class="language-python">df.head()
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>AC</th>
<th>AF</th>
<th>AR</th>
<th>AS</th>
<th>AST</th>
<th>AY</th>
<th>AwayTeam</th>
<th>B365A</th>
<th>B365D</th>
<th>B365H</th>
<th>BWA</th>
<th>BWD</th>
<th>BWH</th>
<th>Bb1X2</th>
<th>BbAH</th>
<th>BbAHh</th>
<th>BbAv&lt;2.5</th>
<th>BbAv&gt;2.5</th>
<th>BbAvA</th>
<th>BbAvAHA</th>
<th>BbAvAHH</th>
<th>BbAvD</th>
<th>BbAvH</th>
<th>BbMx&lt;2.5</th>
<th>BbMx&gt;2.5</th>
<th>BbMxA</th>
<th>BbMxAHA</th>
<th>BbMxAHH</th>
<th>BbMxD</th>
<th>BbMxH</th>
<th>BbOU</th>
<th>Date</th>
<th>Day</th>
<th>Div</th>
<th>FTAG</th>
<th>FTHG</th>
<th>FTR</th>
<th>HC</th>
<th>HF</th>
<th>HR</th>
<th>HS</th>
<th>HST</th>
<th>HTAG</th>
<th>HTHG</th>
<th>HTR</th>
<th>HY</th>
<th>HomeTeam</th>
<th>IWA</th>
<th>IWD</th>
<th>IWH</th>
<th>LBA</th>
<th>LBD</th>
<th>LBH</th>
<th>Month</th>
<th>Referee</th>
<th>VCA</th>
<th>VCD</th>
<th>VCH</th>
<th>Year</th>
<th>season</th>
<th>gameId</th>
<th>homeWin</th>
<th>awayWin</th>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>6.0</td>
<td>14.0</td>
<td>1.0</td>
<td>11.0</td>
<td>5.0</td>
<td>1.0</td>
<td>Blackburn</td>
<td>2.75</td>
<td>3.20</td>
<td>2.50</td>
<td>2.90</td>
<td>3.30</td>
<td>2.20</td>
<td>55.0</td>
<td>20.0</td>
<td>0.00</td>
<td>1.71</td>
<td>2.02</td>
<td>2.74</td>
<td>2.04</td>
<td>1.82</td>
<td>3.16</td>
<td>2.40</td>
<td>1.80</td>
<td>2.25</td>
<td>2.90</td>
<td>2.08</td>
<td>1.86</td>
<td>3.35</td>
<td>2.60</td>
<td>35.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>1.0</td>
<td>3.0</td>
<td>H</td>
<td>2.0</td>
<td>11.0</td>
<td>0.0</td>
<td>13.0</td>
<td>5.0</td>
<td>1.0</td>
<td>0.0</td>
<td>A</td>
<td>0.0</td>
<td>West Ham</td>
<td>2.7</td>
<td>3.0</td>
<td>2.3</td>
<td>2.75</td>
<td>3.00</td>
<td>2.38</td>
<td>8</td>
<td>A Wiley</td>
<td>2.75</td>
<td>3.25</td>
<td>2.40</td>
<td>2005</td>
<td>0506</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>home</td>
</tr>
<tr>
<td>1</td>
<td>8.0</td>
<td>16.0</td>
<td>0.0</td>
<td>13.0</td>
<td>6.0</td>
<td>2.0</td>
<td>Bolton</td>
<td>3.00</td>
<td>3.25</td>
<td>2.30</td>
<td>3.15</td>
<td>3.25</td>
<td>2.10</td>
<td>56.0</td>
<td>22.0</td>
<td>-0.25</td>
<td>1.70</td>
<td>2.01</td>
<td>3.05</td>
<td>1.84</td>
<td>2.01</td>
<td>3.16</td>
<td>2.20</td>
<td>1.87</td>
<td>2.20</td>
<td>3.40</td>
<td>1.92</td>
<td>2.10</td>
<td>3.30</td>
<td>2.40</td>
<td>36.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>2.0</td>
<td>2.0</td>
<td>D</td>
<td>7.0</td>
<td>14.0</td>
<td>0.0</td>
<td>3.0</td>
<td>2.0</td>
<td>2.0</td>
<td>2.0</td>
<td>D</td>
<td>0.0</td>
<td>Aston Villa</td>
<td>3.1</td>
<td>3.0</td>
<td>2.1</td>
<td>3.20</td>
<td>3.00</td>
<td>2.10</td>
<td>8</td>
<td>M Riley</td>
<td>3.10</td>
<td>3.25</td>
<td>2.20</td>
<td>2005</td>
<td>0506</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>draw</td>
</tr>
<tr>
<td>2</td>
<td>6.0</td>
<td>14.0</td>
<td>0.0</td>
<td>12.0</td>
<td>5.0</td>
<td>1.0</td>
<td>Man United</td>
<td>1.72</td>
<td>3.40</td>
<td>5.00</td>
<td>1.75</td>
<td>3.35</td>
<td>4.35</td>
<td>56.0</td>
<td>23.0</td>
<td>0.75</td>
<td>1.79</td>
<td>1.93</td>
<td>1.69</td>
<td>1.86</td>
<td>2.00</td>
<td>3.36</td>
<td>4.69</td>
<td>1.87</td>
<td>2.10</td>
<td>1.80</td>
<td>1.93</td>
<td>2.05</td>
<td>3.70</td>
<td>5.65</td>
<td>36.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>2.0</td>
<td>0.0</td>
<td>A</td>
<td>8.0</td>
<td>15.0</td>
<td>0.0</td>
<td>10.0</td>
<td>5.0</td>
<td>1.0</td>
<td>0.0</td>
<td>A</td>
<td>3.0</td>
<td>Everton</td>
<td>1.8</td>
<td>3.1</td>
<td>3.8</td>
<td>1.83</td>
<td>3.20</td>
<td>3.75</td>
<td>8</td>
<td>G Poll</td>
<td>1.80</td>
<td>3.30</td>
<td>4.50</td>
<td>2005</td>
<td>0506</td>
<td>3</td>
<td>0</td>
<td>1</td>
<td>away</td>
</tr>
<tr>
<td>3</td>
<td>6.0</td>
<td>13.0</td>
<td>0.0</td>
<td>7.0</td>
<td>4.0</td>
<td>2.0</td>
<td>Birmingham</td>
<td>2.87</td>
<td>3.25</td>
<td>2.37</td>
<td>2.80</td>
<td>3.20</td>
<td>2.30</td>
<td>56.0</td>
<td>21.0</td>
<td>0.00</td>
<td>1.69</td>
<td>2.04</td>
<td>2.87</td>
<td>2.05</td>
<td>1.81</td>
<td>3.16</td>
<td>2.31</td>
<td>1.77</td>
<td>2.24</td>
<td>3.05</td>
<td>2.11</td>
<td>1.85</td>
<td>3.30</td>
<td>2.60</td>
<td>36.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>6.0</td>
<td>12.0</td>
<td>0.0</td>
<td>15.0</td>
<td>7.0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>1.0</td>
<td>Fulham</td>
<td>2.9</td>
<td>3.0</td>
<td>2.2</td>
<td>2.88</td>
<td>3.00</td>
<td>2.25</td>
<td>8</td>
<td>R Styles</td>
<td>2.80</td>
<td>3.25</td>
<td>2.35</td>
<td>2005</td>
<td>0506</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>draw</td>
</tr>
<tr>
<td>4</td>
<td>6.0</td>
<td>11.0</td>
<td>0.0</td>
<td>13.0</td>
<td>3.0</td>
<td>3.0</td>
<td>West Brom</td>
<td>5.00</td>
<td>3.40</td>
<td>1.72</td>
<td>4.80</td>
<td>3.45</td>
<td>1.65</td>
<td>55.0</td>
<td>23.0</td>
<td>-0.75</td>
<td>1.77</td>
<td>1.94</td>
<td>4.79</td>
<td>1.76</td>
<td>2.10</td>
<td>3.38</td>
<td>1.69</td>
<td>1.90</td>
<td>2.10</td>
<td>5.60</td>
<td>1.83</td>
<td>2.19</td>
<td>3.63</td>
<td>1.80</td>
<td>36.0</td>
<td>2005-08-13</td>
<td>13</td>
<td>E0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>3.0</td>
<td>13.0</td>
<td>0.0</td>
<td>15.0</td>
<td>8.0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>2.0</td>
<td>Man City</td>
<td>4.2</td>
<td>3.2</td>
<td>1.7</td>
<td>4.50</td>
<td>3.25</td>
<td>1.67</td>
<td>8</td>
<td>C Foy</td>
<td>5.00</td>
<td>3.25</td>
<td>1.75</td>
<td>2005</td>
<td>0506</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>draw</td>
</tr>
</tbody>
</table>
<p>Now we need to specify which game week we would like to predict. We will then filter the fixture for this game week and append this info to the main DataFrame</p>
<pre><code class="language-python">round_to_predict = int(input(&quot;Which game week would you like to predict? Please input next week's Game Week\n&quot;))
</code></pre>
<pre><code>Which game week would you like to predict? Please input next week's Game Week
4
</code></pre>
<pre><code class="language-python">future_predictions = (fixture.loc[fixture['round'] == round_to_predict, ['Date', 'HomeTeam', 'AwayTeam', 'season']]
                             .pipe(pd.merge, odds, on=['HomeTeam', 'AwayTeam'])
                             .rename(columns={
                                 'f_homeOdds': 'B365H',
                                 'f_awayOdds': 'B365A',
                                 'f_drawOdds': 'B365D'})
                             .assign(season=lambda df: df.season.astype(str)))
</code></pre>
<pre><code class="language-python">df_including_future_games = (pd.read_csv('data/epl_data.csv', dtype={'season': str})
                .assign(Date=lambda df: pd.to_datetime(df.Date))
                .pipe(lambda df: df.dropna(thresh=len(df) - 2, axis=1))  # Drop cols with NAs
                .dropna(axis=0)  # Drop rows with NAs
                .sort_values('Date')
                .append(future_predictions, sort=True)
                .reset_index(drop=True)
                .assign(gameId=lambda df: list(df.index + 1),
                            Year=lambda df: df.Date.apply(lambda row: row.year),
                            homeWin=lambda df: df.apply(lambda row: 1 if row.FTHG &gt; row.FTAG else 0, axis=1),
                            awayWin=lambda df: df.apply(lambda row: 1 if row.FTAG &gt; row.FTHG else 0, axis=1),
                            result=lambda df: df.apply(lambda row: 'home' if row.FTHG &gt; row.FTAG else ('draw' if row.FTHG == row.FTAG else 'away'), axis=1)))
</code></pre>
<pre><code class="language-python">df_including_future_games.tail(12)
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>AC</th>
<th>AF</th>
<th>AR</th>
<th>AS</th>
<th>AST</th>
<th>AY</th>
<th>AwayTeam</th>
<th>B365A</th>
<th>B365D</th>
<th>B365H</th>
<th>BWA</th>
<th>BWD</th>
<th>BWH</th>
<th>Bb1X2</th>
<th>BbAH</th>
<th>BbAHh</th>
<th>BbAv&lt;2.5</th>
<th>BbAv&gt;2.5</th>
<th>BbAvA</th>
<th>BbAvAHA</th>
<th>BbAvAHH</th>
<th>BbAvD</th>
<th>BbAvH</th>
<th>BbMx&lt;2.5</th>
<th>BbMx&gt;2.5</th>
<th>BbMxA</th>
<th>BbMxAHA</th>
<th>BbMxAHH</th>
<th>BbMxD</th>
<th>BbMxH</th>
<th>BbOU</th>
<th>Date</th>
<th>Day</th>
<th>Div</th>
<th>FTAG</th>
<th>FTHG</th>
<th>FTR</th>
<th>HC</th>
<th>HF</th>
<th>HR</th>
<th>HS</th>
<th>HST</th>
<th>HTAG</th>
<th>HTHG</th>
<th>HTR</th>
<th>HY</th>
<th>HomeTeam</th>
<th>IWA</th>
<th>IWD</th>
<th>IWH</th>
<th>LBA</th>
<th>LBD</th>
<th>LBH</th>
<th>Month</th>
<th>Referee</th>
<th>VCA</th>
<th>VCD</th>
<th>VCH</th>
<th>Year</th>
<th>season</th>
<th>gameId</th>
<th>homeWin</th>
<th>awayWin</th>
<th>result</th>
</tr>
</thead>
<tbody>
<tr>
<td>4952</td>
<td>4.0</td>
<td>8.0</td>
<td>0.0</td>
<td>12.0</td>
<td>2.0</td>
<td>1.0</td>
<td>Burnley</td>
<td>4.33</td>
<td>3.40</td>
<td>2.00</td>
<td>4.0</td>
<td>3.3</td>
<td>2.00</td>
<td>39.0</td>
<td>20.0</td>
<td>-0.25</td>
<td>1.65</td>
<td>2.22</td>
<td>4.14</td>
<td>2.22</td>
<td>1.69</td>
<td>3.36</td>
<td>1.98</td>
<td>1.72</td>
<td>2.31</td>
<td>4.5</td>
<td>2.32</td>
<td>1.74</td>
<td>3.57</td>
<td>2.04</td>
<td>36.0</td>
<td>2018-08-26</td>
<td>26.0</td>
<td>E0</td>
<td>2.0</td>
<td>4.0</td>
<td>H</td>
<td>6.0</td>
<td>11.0</td>
<td>0.0</td>
<td>25.0</td>
<td>12.0</td>
<td>2.0</td>
<td>3.0</td>
<td>H</td>
<td>2.0</td>
<td>Fulham</td>
<td>4.10</td>
<td>3.35</td>
<td>1.97</td>
<td>3.90</td>
<td>3.2</td>
<td>2.00</td>
<td>8.0</td>
<td>D Coote</td>
<td>4.33</td>
<td>3.4</td>
<td>2.0</td>
<td>2018</td>
<td>1819</td>
<td>4953</td>
<td>1</td>
<td>0</td>
<td>home</td>
</tr>
<tr>
<td>4953</td>
<td>2.0</td>
<td>16.0</td>
<td>0.0</td>
<td>9.0</td>
<td>5.0</td>
<td>4.0</td>
<td>Tottenham</td>
<td>2.90</td>
<td>3.30</td>
<td>2.62</td>
<td>2.9</td>
<td>3.2</td>
<td>2.55</td>
<td>42.0</td>
<td>20.0</td>
<td>-0.25</td>
<td>1.79</td>
<td>2.03</td>
<td>2.86</td>
<td>1.72</td>
<td>2.18</td>
<td>3.27</td>
<td>2.56</td>
<td>1.84</td>
<td>2.10</td>
<td>3.0</td>
<td>1.76</td>
<td>2.25</td>
<td>3.40</td>
<td>2.67</td>
<td>40.0</td>
<td>2018-08-27</td>
<td>27.0</td>
<td>E0</td>
<td>3.0</td>
<td>0.0</td>
<td>A</td>
<td>5.0</td>
<td>11.0</td>
<td>0.0</td>
<td>23.0</td>
<td>5.0</td>
<td>0.0</td>
<td>0.0</td>
<td>D</td>
<td>2.0</td>
<td>Man United</td>
<td>2.75</td>
<td>3.25</td>
<td>2.60</td>
<td>2.75</td>
<td>3.2</td>
<td>2.55</td>
<td>8.0</td>
<td>C Pawson</td>
<td>2.90</td>
<td>3.3</td>
<td>2.6</td>
<td>2018</td>
<td>1819</td>
<td>4954</td>
<td>0</td>
<td>1</td>
<td>away</td>
</tr>
<tr>
<td>4954</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Liverpool</td>
<td>1.48</td>
<td>5.10</td>
<td>7.80</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-01</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Leicester</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4955</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4955</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Fulham</td>
<td>3.50</td>
<td>3.50</td>
<td>2.36</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Brighton</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4956</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4956</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Man United</td>
<td>1.70</td>
<td>3.90</td>
<td>6.60</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Burnley</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4957</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4957</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Bournemouth</td>
<td>12.00</td>
<td>6.80</td>
<td>1.32</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Chelsea</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4958</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4958</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Southampton</td>
<td>4.50</td>
<td>3.55</td>
<td>2.04</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Crystal Palace</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4959</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4959</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Huddersfield</td>
<td>8.20</td>
<td>4.40</td>
<td>1.54</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Everton</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4960</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4960</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Wolves</td>
<td>2.98</td>
<td>3.50</td>
<td>2.62</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>West Ham</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4961</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4961</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Newcastle</td>
<td>32.00</td>
<td>12.50</td>
<td>1.12</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Man City</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4962</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4962</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Arsenal</td>
<td>1.62</td>
<td>4.30</td>
<td>7.00</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-02</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Cardiff</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4963</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
<tr>
<td>4963</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Tottenham</td>
<td>1.68</td>
<td>4.30</td>
<td>5.90</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018-09-03</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>Watford</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>2018</td>
<td>1819</td>
<td>4964</td>
<td>0</td>
<td>0</td>
<td>away</td>
</tr>
</tbody>
</table>
<p>As we can see, what we have done is appended the Game information to our main DataFrame. The rest of the info is left as NAs, but this will be filled when we created our rolling average features. This is a 'hacky' type of way to complete this task, but works well as we can use the same functions that we created in the previous tutorials on this DataFrame. We now need to add the odds from our odds DataFrame, then we can just run our create features functions as usual.</p>
<hr />
<h2 id="predicting-next-gameweeks-results">Predicting Next Gameweek's Results</h2>
<p>Now that we have our feature DataFrame, all we need to do is split the feature DataFrame up into a training set and next week's games, then use the model we tuned in the last tutorial to create predictions!</p>
<pre><code class="language-python">features = create_feature_df(df=df_including_future_games)

    Creating all games feature DataFrame
    Creating stats feature DataFrame
    Creating odds feature DataFrame
    Creating market values feature DataFrame
    Filling NAs
    Merging stats, odds and market values into one features DataFrame
    Complete.
</code></pre>
<pre><code class="language-python"># Create a feature DataFrame for this week's games.
production_df = pd.merge(future_predictions, features, on=['Date', 'HomeTeam', 'AwayTeam', 'season'])
</code></pre>
<pre><code class="language-python"># Create a training DataFrame
training_df = features[~features.gameId.isin(production_df.gameId)]
</code></pre>
<pre><code class="language-python">feature_names = [col for col in training_df if col.startswith('f_')]

le = LabelEncoder()
train_y = le.fit_transform(training_df.result)
train_x = training_df[feature_names]
</code></pre>
<pre><code class="language-python">lr = LogisticRegression(C=0.01, solver='liblinear')
lr.fit(train_x, train_y)
predicted_probs = lr.predict_proba(production_df[feature_names])
predicted_odds = 1 / predicted_probs
</code></pre>
<pre><code class="language-python"># Assign the modelled odds to our predictions df
predictions_df = (production_df.loc[:, ['Date', 'HomeTeam', 'AwayTeam', 'B365H', 'B365D', 'B365A']]
                               .assign(homeModelledOdds=[i[2] for i in predicted_odds],
                                      drawModelledOdds=[i[1] for i in predicted_odds],
                                      awayModelledOdds=[i[0] for i in predicted_odds])
                               .rename(columns={
                                   'B365H': 'BetfairHomeOdds',
                                   'B365D': 'BetfairDrawOdds',
                                   'B365A': 'BetfairAwayOdds'}))
</code></pre>
<pre><code class="language-python">predictions_df
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th>Date</th>
<th>HomeTeam</th>
<th>AwayTeam</th>
<th>BetfairHomeOdds</th>
<th>BetfairDrawOdds</th>
<th>BetfairAwayOdds</th>
<th>homeModelledOdds</th>
<th>drawModelledOdds</th>
<th>awayModelledOdds</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>2018-09-01</td>
<td>Leicester</td>
<td>Liverpool</td>
<td>7.80</td>
<td>5.10</td>
<td>1.48</td>
<td>5.747661</td>
<td>5.249857</td>
<td>1.573478</td>
</tr>
<tr>
<td>1</td>
<td>2018-09-02</td>
<td>Brighton</td>
<td>Fulham</td>
<td>2.36</td>
<td>3.50</td>
<td>3.50</td>
<td>2.183193</td>
<td>3.803120</td>
<td>3.584057</td>
</tr>
<tr>
<td>2</td>
<td>2018-09-02</td>
<td>Burnley</td>
<td>Man United</td>
<td>6.60</td>
<td>3.90</td>
<td>1.70</td>
<td>5.282620</td>
<td>4.497194</td>
<td>1.699700</td>
</tr>
<tr>
<td>3</td>
<td>2018-09-02</td>
<td>Chelsea</td>
<td>Bournemouth</td>
<td>1.32</td>
<td>6.80</td>
<td>12.00</td>
<td>1.308366</td>
<td>6.079068</td>
<td>14.047070</td>
</tr>
<tr>
<td>4</td>
<td>2018-09-02</td>
<td>Crystal Palace</td>
<td>Southampton</td>
<td>2.04</td>
<td>3.55</td>
<td>4.50</td>
<td>2.202871</td>
<td>4.213695</td>
<td>3.239122</td>
</tr>
<tr>
<td>5</td>
<td>2018-09-02</td>
<td>Everton</td>
<td>Huddersfield</td>
<td>1.54</td>
<td>4.40</td>
<td>8.20</td>
<td>1.641222</td>
<td>3.759249</td>
<td>8.020055</td>
</tr>
<tr>
<td>6</td>
<td>2018-09-02</td>
<td>West Ham</td>
<td>Wolves</td>
<td>2.62</td>
<td>3.50</td>
<td>2.98</td>
<td>1.999816</td>
<td>4.000456</td>
<td>4.000279</td>
</tr>
<tr>
<td>7</td>
<td>2018-09-02</td>
<td>Man City</td>
<td>Newcastle</td>
<td>1.12</td>
<td>12.50</td>
<td>32.00</td>
<td>1.043103</td>
<td>29.427939</td>
<td>136.231983</td>
</tr>
<tr>
<td>8</td>
<td>2018-09-02</td>
<td>Cardiff</td>
<td>Arsenal</td>
<td>7.00</td>
<td>4.30</td>
<td>1.62</td>
<td>6.256929</td>
<td>4.893445</td>
<td>1.572767</td>
</tr>
<tr>
<td>9</td>
<td>2018-09-03</td>
<td>Watford</td>
<td>Tottenham</td>
<td>5.90</td>
<td>4.30</td>
<td>1.68</td>
<td>5.643663</td>
<td>4.338926</td>
<td>1.688224</td>
</tr>
</tbody>
</table>
<p>Above are the predictions for this Gameweek's matches. In the next tutorial we will explore the errors our model has made, and work on creating a profitable betting strategy.</p>
<hr />
<h3 id="disclaimer">Disclaimer</h3>
<p>Note that whilst models and automated strategies are fun and rewarding to create, we can't promise that your model or betting strategy will be profitable, and we make no representations in relation to the code shared or information on this page. If you're using this code or implementing your own strategies, you do so entirely at your own risk and you are responsible for any winnings/losses incurred. Under no circumstances will Betfair be liable for any loss or damage you suffer.</p>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
    
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../soccerModellingTutorialR/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Soccer modelling tutorial in R" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Previous
                </span>
                Soccer modelling tutorial in R
              </div>
            </div>
          </a>
        
        
          
          <a href="../AFLmodellingPython/" class="md-footer__link md-footer__link--next" aria-label="Next: AFL modelling walk through in Python" rel="next">
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Next
                </span>
                AFL modelling walk through in Python
              </div>
            </div>
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-copyright">
  
  
</div>
        
          <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/Betfair_Aus" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://linkedin.com/company/betfair-australia" target="_blank" rel="noopener" title="linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://facebook.com/betfairaustralia" target="_blank" rel="noopener" title="facebook.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://youtube.com/user/betfairaus" target="_blank" rel="noopener" title="youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://github.com/betfair-datascientists" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
        
      </div>

      <div class="bf-footer">
          <div class="bf-footer-inner">
              <p class="bf-light">Betfair Pty Limited is licensed and regulated by the Northern Territory Government of Australia.</p>
              <p class="bf-dark">Betfair Pty Limited's gambling operations are governed by its Responsible Gambling Code of Conduct and for South
              Australian residents by the South Australian Responsible Gambling Code of Practice.<br /> Think! About your choices. Don’t let the game play you. Stay in control. Gamble responsibly. Call Gambling Help 1800 858 858 <a href="https://gamblinghelponline.org.au">www.gamblinghelponline.org.au</a></p>
          
              <ul class="bf-links">
                <li><a href="https://www.betfair.com.au/hub/help/account-help/responsible-gambling/">Responsible Gambling</a><span>|</span></li>
                <li><a href="http://www.betfair.com/AUS_NZL/aboutUs/Terms.and.Conditions/">Terms & Conditions</a><span>|</span></li>
                <li><a href="https://www.betfair.com.au/info/privacy-policy/">Privacy Policy</a><span>|</span></li>
                <li><a href="http://www.betfair.com/en/aboutUs/Rules.and.Regulations/">Rules & Regulations</a><span>|</span></li>
                <li><a href="https://www.betfair.com/AUS_NZL/aboutUs/Dispute.Resolution">Dispute Resolution</a></li>
              </ul>
          </div>
      </div>
    </div>

    <script src="https://js.adsrvr.org/up_loader.1.1.0.js" type="text/javascript"></script>
    <script type="text/javascript">
        ttd_dom_ready( function() {
            if (typeof TTDUniversalPixelApi === 'function') {
                var universalPixelApi = new TTDUniversalPixelApi();
                universalPixelApi.init("y12d1ir", ["8ml4f17"], "https://insight.adsrvr.org/track/up");
            }
        });
    </script>

</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../../assets/javascripts/bundle.1514a9a0.min.js"></script>
      
    
  </body>
</html>