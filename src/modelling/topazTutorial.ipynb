{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greyhound Modelling in Python using the Topaz API\n",
    "Building a greyhound racing model using Python and Machine Learning\n",
    "\n",
    "This tutorial is a refreshed version of our previous tutorials utilising the new version of the FastTrack API (now called Topaz). \n",
    "Topaz is a product provided to Betfair Australia & New Zealand customers by Greyhound Racing Victoria (GRV). \n",
    "\n",
    "If you would like your own Topaz API key, please contact us [here](mailto:data@betfair.com.au). \n",
    "Access can only be provided to Betfair Australia or New Zealand customers with active accounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Overview\n",
    "This tutorial will walk you through the different steps required to generate Greyhound racing winning probabilities\n",
    "\n",
    "1. Download historic greyhound data from Topaz API\n",
    "1. Cleanse and normalise the data\n",
    "1. Generate features using raw data\n",
    "1. Build and train classification models\n",
    "1. Evaluate models' performances\n",
    "1. Evaluate feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Requirements\n",
    "- Coding environment which supports Jupyter Notebooks (e.g. Visual Studio Code)\n",
    "- Betfair API Key. If you don't have one please follow the steps outlined on the [The Automation Hub](https://betfair-datascientists.github.io/api/apiappkey/)\n",
    "- Topaz API Key. If you would like to be considered for a Topaz key, please email [data@betfair.com.au](mailto:data@betfair.com.au) (Australian/New Zealand customers only).\n",
    "- Python Topaz API wrapper. To install this package using pip, type 'pip install topaz_api' into your terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Historic Data\n",
    "To get started on building our own Topaz model, first we need to download the historic data from the Topaz API. The API has rate limits in place and so for the purposes of a bulk download of historic data, we will need to implement some way of handling these rate limits in order for us to download the data with a high degree of completeness. After all, the maxim 'Garbage In, Garbage Out' in regards to modelling holds true. If you don't feed your model good, complete data, then you won't have much success.\n",
    "\n",
    "In the code block below, there are multiple instances of retries and programmed sleep functions to allow the rate limits to reset. We are also requesting the races for each state in blocks of 7 days.\n",
    "\n",
    "NOTE: For state / date-range combinations where there are genuinely no races that occurred, the function will continuously error until it reaches the maximum specified retries before continuing to the next block. This may occur during the pandemic shutdown period in 2020 or the NSW Greyhound racing ban in 2017 or for time periods with the 'NT' jurisdiction where greyhound meetings may be up to 14 days apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from topaz import TopazAPI\n",
    "\n",
    "api_key = ''  # Insert your API key\n",
    "topaz_api = TopazAPI(api_key)\n",
    "\n",
    "# Generate a date range\n",
    "def generate_date_range(start_date, end_date):\n",
    "    start_date = start_date\n",
    "    end_date = end_date\n",
    "\n",
    "    date_list = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_list.append(current_date.strftime(\"%Y-%m-%d\"))\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return date_list\n",
    "\n",
    "# Input the number of days of historical data required\n",
    "# To input absolute dates rather than a timedelta use 'datetime(YYYY,M,D)'\n",
    "start_date = (datetime.today() - timedelta(days=365))\n",
    "end_date = (datetime.today() - timedelta(days=1))\n",
    "\n",
    "# Generate the date range\n",
    "date_range = generate_date_range(start_date, end_date)\n",
    "\n",
    "# Iterate over 7-day blocks\n",
    "for i in range(0, len(date_range), 6):\n",
    "    start_block_date = date_range[i]\n",
    "    print(start_block_date)\n",
    "    end_block_date = date_range[min(i + 6, len(date_range) - 1)]  # Ensure the end date is within the range\n",
    "\n",
    "    codes = ['NZ', 'NT', 'VIC', 'NSW', 'SA', 'WA', 'QLD', 'TAS']\n",
    "\n",
    "    for code in codes:\n",
    "        all_races = []\n",
    "        print(code)\n",
    "        retries = 10  # Number of retries\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                races = topaz_api.get_races(from_date=start_block_date, to_date=end_block_date, owning_authority_code=code)\n",
    "                all_races.append(races)\n",
    "                break  # Break out of the loop if successful\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching races for {code}: {e}\")\n",
    "                retries -= 1\n",
    "                if retries > 0:\n",
    "                    print(f\"Retrying in 30 seconds...\")\n",
    "                    time.sleep(30)\n",
    "                else:\n",
    "                    print(\"Max retries reached. Moving to the next block.\")\n",
    "\n",
    "        try:\n",
    "            all_races_df = pd.concat(all_races, ignore_index=True)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # Extract unique race IDs\n",
    "        race_ids = list(all_races_df['raceId'].unique())\n",
    "\n",
    "        for race_id in tqdm(race_ids, desc=\"Processing races\", unit=\"race\"):\n",
    "            result_retries = 10\n",
    "\n",
    "            while result_retries >/ 0:\n",
    "                # Use tqdm to create a progress bar\n",
    "                # Get race run data\n",
    "                try:\n",
    "                    race_run = topaz_api.get_race_runs(race_id=race_id)\n",
    "                    file_path = code + '_DATA.csv'\n",
    "                    file_exists = os.path.isfile(file_path)\n",
    "                    header_param = not file_exists\n",
    "                    race_run.to_csv(code + '_DATA.csv', mode='a', header=header_param, index=False)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    result_retries -= 1\n",
    "                    if result_retries > 0:\n",
    "                        time.sleep(15)\n",
    "                    else:\n",
    "                        time.sleep(120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The Topaz race results endpoint requires the passing of a jurisdiction ID as a parameter to pull the results. Simply passing a date range will return no data. This is why we have looped over all jurisdictions in 7 day blocks.\n",
    "\n",
    "Bulk downloading the historical data in this way may take a while depending on how many years of data you are requesting. Bruno, the author of one of our previous greyhound modelling tutorials, uses 6 years worth of data for his backtesting. This however is computationally expensive to process in a machine learning model, so we suggest 2-3 years for those just starting out. \n",
    "\n",
    "NOTE: In the above code we have exported each state separately to its own csv file. This will keep each file under a million rows ensuring that you can manually inspect the data by opening the file in Excel. This is not required (we will pull in each file to our model before we begin to process the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be continued..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Note that whilst models and automated strategies are fun and rewarding to create, we can't promise that your model or betting strategy will be profitable, and we make no representations in relation to the code shared or information on this page. If you're using this code or implementing your own strategies, you do so entirely at your own risk and you are responsible for any winnings/losses incurred. Under no circumstances will Betfair be liable for any loss or damage you suffer."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
